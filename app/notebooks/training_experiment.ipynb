{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Akechi1412/Phishing-Website-Detection/blob/main/app/notebooks/training_experiment.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ie97YpRCETlO"
      },
      "source": [
        "# **Train Phishing Webpage Detection Model (Experiment)**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JWJeAJ4MEkBz"
      },
      "source": [
        "## **Connect to Drive and Github responsitory**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GFR4qI0yDyXW",
        "outputId": "6ebab958-66ab-4694-9056-48ad9d0cb777"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kRvWxHJVEqiV",
        "outputId": "836c1fde-ce62-49c4-f965-377dc5fd37b8"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/drive/MyDrive/Github\n",
            "/content/drive/MyDrive/Github/Phishing-Website-Detection/app\n"
          ]
        }
      ],
      "source": [
        "%cd /content/drive/MyDrive/Github\n",
        "%cd Phishing-Website-Detection/app\n",
        "# !git config --global user.email 'nguyenphong10042002@gmail.com'\n",
        "# !git config --global user.name 'Akechi1412'\n",
        "# !git fetch origin\n",
        "# !git reset --hard origin/main"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ND63uFHUXK9M"
      },
      "source": [
        "## **Load dataset**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "xOnT0W5UMd4S"
      },
      "outputs": [],
      "source": [
        "import h5py\n",
        "import tensorflow as tf"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def load_html_dataset(file_path, batch_size=1024):\n",
        "    with h5py.File(file_path, 'r') as f:\n",
        "        adjacency_data = f['adjacency']\n",
        "        feature_data = f['feature']\n",
        "        label_data = f['label']\n",
        "\n",
        "        num_samples = label_data.shape[0]\n",
        "\n",
        "        dataset = tf.data.Dataset.from_tensor_slices((\n",
        "            (\n",
        "                tf.convert_to_tensor(adjacency_data, dtype=tf.float32),\n",
        "                tf.convert_to_tensor(feature_data, dtype=tf.float32)\n",
        "            ),\n",
        "            tf.convert_to_tensor(label_data, dtype=tf.int32)\n",
        "        ))\n",
        "\n",
        "    dataset = dataset.batch(batch_size).prefetch(tf.data.experimental.AUTOTUNE)\n",
        "\n",
        "    return dataset"
      ],
      "metadata": {
        "id": "yBh3YXqPhn9N"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def load_dataset(file_path, batch_size=1024):\n",
        "    with h5py.File(file_path, 'r') as f:\n",
        "        url_data = f['url']\n",
        "        adjacency_data = f['adjacency']\n",
        "        feature_data = f['feature']\n",
        "        label_data = f['label']\n",
        "\n",
        "        num_samples = label_data.shape[0]\n",
        "\n",
        "        dataset = tf.data.Dataset.from_tensor_slices((\n",
        "            (\n",
        "                tf.convert_to_tensor(url_data, dtype=tf.int32),\n",
        "                tf.convert_to_tensor(adjacency_data, dtype=tf.float32),\n",
        "                tf.convert_to_tensor(feature_data, dtype=tf.float32)\n",
        "            ),\n",
        "            tf.convert_to_tensor(label_data, dtype=tf.int32)\n",
        "        ))\n",
        "\n",
        "    dataset = dataset.batch(batch_size).prefetch(tf.data.experimental.AUTOTUNE)\n",
        "\n",
        "    return dataset"
      ],
      "metadata": {
        "id": "iby6gLzDgME-"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GBMOCOvAae_w"
      },
      "source": [
        "## **Train and evaluate model**"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install spektral"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "p4mIrltDk8Tf",
        "outputId": "4bfe0859-9811-4ae6-dc59-acccc22fce7e"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting spektral\n",
            "  Downloading spektral-1.3.1-py3-none-any.whl.metadata (5.9 kB)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.10/dist-packages (from spektral) (1.4.2)\n",
            "Collecting lxml (from spektral)\n",
            "  Downloading lxml-5.3.0-cp310-cp310-manylinux_2_28_x86_64.whl.metadata (3.8 kB)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from spektral) (3.4.2)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from spektral) (1.26.4)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (from spektral) (2.2.2)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from spektral) (2.32.3)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.10/dist-packages (from spektral) (1.6.0)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.10/dist-packages (from spektral) (1.13.1)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from spektral) (4.67.1)\n",
            "Requirement already satisfied: tensorflow>=2.2.0 in /usr/local/lib/python3.10/dist-packages (from spektral) (2.15.0)\n",
            "Requirement already satisfied: absl-py>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow>=2.2.0->spektral) (1.4.0)\n",
            "Requirement already satisfied: astunparse>=1.6.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow>=2.2.0->spektral) (1.6.3)\n",
            "Requirement already satisfied: flatbuffers>=23.5.26 in /usr/local/lib/python3.10/dist-packages (from tensorflow>=2.2.0->spektral) (24.3.25)\n",
            "Requirement already satisfied: gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow>=2.2.0->spektral) (0.6.0)\n",
            "Requirement already satisfied: google-pasta>=0.1.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow>=2.2.0->spektral) (0.2.0)\n",
            "Requirement already satisfied: h5py>=2.9.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow>=2.2.0->spektral) (3.12.1)\n",
            "Requirement already satisfied: libclang>=13.0.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow>=2.2.0->spektral) (18.1.1)\n",
            "Requirement already satisfied: ml-dtypes~=0.2.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow>=2.2.0->spektral) (0.2.0)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.10/dist-packages (from tensorflow>=2.2.0->spektral) (3.4.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from tensorflow>=2.2.0->spektral) (24.2)\n",
            "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.20.3 in /usr/local/lib/python3.10/dist-packages (from tensorflow>=2.2.0->spektral) (4.25.5)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from tensorflow>=2.2.0->spektral) (75.1.0)\n",
            "Requirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow>=2.2.0->spektral) (1.17.0)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow>=2.2.0->spektral) (2.5.0)\n",
            "Requirement already satisfied: typing-extensions>=3.6.6 in /usr/local/lib/python3.10/dist-packages (from tensorflow>=2.2.0->spektral) (4.12.2)\n",
            "Requirement already satisfied: wrapt<1.15,>=1.11.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow>=2.2.0->spektral) (1.14.1)\n",
            "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow>=2.2.0->spektral) (0.37.1)\n",
            "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /usr/local/lib/python3.10/dist-packages (from tensorflow>=2.2.0->spektral) (1.68.1)\n",
            "Requirement already satisfied: tensorboard<2.16,>=2.15 in /usr/local/lib/python3.10/dist-packages (from tensorflow>=2.2.0->spektral) (2.15.2)\n",
            "Requirement already satisfied: tensorflow-estimator<2.16,>=2.15.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow>=2.2.0->spektral) (2.15.0)\n",
            "Requirement already satisfied: keras<2.16,>=2.15.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow>=2.2.0->spektral) (2.15.0)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from pandas->spektral) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas->spektral) (2024.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.10/dist-packages (from pandas->spektral) (2024.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->spektral) (3.4.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->spektral) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->spektral) (2.2.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->spektral) (2024.12.14)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn->spektral) (3.5.0)\n",
            "Requirement already satisfied: wheel<1.0,>=0.23.0 in /usr/local/lib/python3.10/dist-packages (from astunparse>=1.6.0->tensorflow>=2.2.0->spektral) (0.45.1)\n",
            "Requirement already satisfied: google-auth<3,>=1.6.3 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.16,>=2.15->tensorflow>=2.2.0->spektral) (2.27.0)\n",
            "Requirement already satisfied: google-auth-oauthlib<2,>=0.5 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.16,>=2.15->tensorflow>=2.2.0->spektral) (1.2.1)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.16,>=2.15->tensorflow>=2.2.0->spektral) (3.7)\n",
            "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.16,>=2.15->tensorflow>=2.2.0->spektral) (0.7.2)\n",
            "Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.16,>=2.15->tensorflow>=2.2.0->spektral) (3.1.3)\n",
            "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.16,>=2.15->tensorflow>=2.2.0->spektral) (5.5.0)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.16,>=2.15->tensorflow>=2.2.0->spektral) (0.4.1)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.16,>=2.15->tensorflow>=2.2.0->spektral) (4.9)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from google-auth-oauthlib<2,>=0.5->tensorboard<2.16,>=2.15->tensorflow>=2.2.0->spektral) (2.0.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.1.1 in /usr/local/lib/python3.10/dist-packages (from werkzeug>=1.0.1->tensorboard<2.16,>=2.15->tensorflow>=2.2.0->spektral) (3.0.2)\n",
            "Requirement already satisfied: pyasn1<0.7.0,>=0.4.6 in /usr/local/lib/python3.10/dist-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard<2.16,>=2.15->tensorflow>=2.2.0->spektral) (0.6.1)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.10/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<2,>=0.5->tensorboard<2.16,>=2.15->tensorflow>=2.2.0->spektral) (3.2.2)\n",
            "Downloading spektral-1.3.1-py3-none-any.whl (140 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m140.1/140.1 kB\u001b[0m \u001b[31m2.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading lxml-5.3.0-cp310-cp310-manylinux_2_28_x86_64.whl (5.0 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.0/5.0 MB\u001b[0m \u001b[31m56.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: lxml, spektral\n",
            "Successfully installed lxml-5.3.0 spektral-1.3.1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers, models, regularizers\n",
        "from spektral.layers import GCNConv, GlobalSumPool\n",
        "from utils.layers import GCN"
      ],
      "metadata": {
        "id": "sbFSgYUHlA8E"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "html_train_dataset = load_html_dataset('data/train.h5', batch_size=128)\n",
        "html_val_dataset = load_html_dataset('data/val.h5', batch_size=128)\n",
        "html_test_dataset = load_html_dataset('data/test.h5', batch_size=128)\n",
        "\n",
        "max_nodes = 600\n",
        "feature_dim = 3"
      ],
      "metadata": {
        "id": "_xzljzRXkq_Y"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Experiment 0**"
      ],
      "metadata": {
        "id": "OoDVWsNAlVHg"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Train model"
      ],
      "metadata": {
        "id": "E43SqaM6livE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def create_html_model(max_nodes, feature_dim, gcn_units, dropout=0.1,\n",
        "                      num_gcn_layers=1, dense_dim=128, l2_reg=5e-4):\n",
        "    inputs_adj = keras.Input(shape=(max_nodes, max_nodes), dtype=tf.float32)\n",
        "    inputs_feat = keras.Input(shape=(max_nodes, feature_dim), dtype=tf.float32)\n",
        "\n",
        "    x = inputs_feat\n",
        "    for _ in range(num_gcn_layers):\n",
        "        x = GCN(gcn_units, activation='relu')([x, inputs_adj])\n",
        "        x = layers.Dropout(dropout)(x)\n",
        "    x = GlobalSumPool()(x)\n",
        "    x = layers.Dense(dense_dim,\n",
        "                     activation='relu',\n",
        "                     kernel_regularizer=regularizers.l2(l2_reg))(x)\n",
        "    x = layers.Dropout(dropout)(x)\n",
        "    x = layers.Dense(dense_dim//2,\n",
        "                     activation='relu',\n",
        "                     kernel_regularizer=regularizers.l2(l2_reg))(x)\n",
        "    x = layers.Dropout(dropout)(x)\n",
        "    outputs = layers.Dense(1, activation='sigmoid')(x)\n",
        "    html_model = keras.Model(inputs=[inputs_adj, inputs_feat], outputs=outputs)\n",
        "\n",
        "    return html_model"
      ],
      "metadata": {
        "id": "B80LH4GblK2V"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = create_html_model(max_nodes=max_nodes,\n",
        "                          feature_dim=feature_dim,\n",
        "                          gcn_units=128,\n",
        "                          num_gcn_layers=2,\n",
        "                          dropout=0.3,\n",
        "                          dense_dim=128,\n",
        "                          l2_reg=5e-4)\n",
        "\n",
        "model.summary()\n",
        "\n",
        "optimizer = keras.optimizers.Adam(learning_rate=1e-3)\n",
        "metrics = ['accuracy', tf.keras.metrics.Precision(), tf.keras.metrics.Recall()]\n",
        "model.compile(optimizer=optimizer, loss='binary_crossentropy', metrics=metrics)\n",
        "\n",
        "checkpoint_filepath = 'models/best_html_model.keras'\n",
        "\n",
        "checkpoint_callback = tf.keras.callbacks.ModelCheckpoint(\n",
        "    filepath=checkpoint_filepath,\n",
        "    save_weights_only=False,\n",
        "    monitor='val_loss',\n",
        "    mode='min',\n",
        "    save_best_only=True,\n",
        "    verbose=1\n",
        ")\n",
        "\n",
        "early_stopping = tf.keras.callbacks.EarlyStopping(\n",
        "    monitor='val_loss',\n",
        "    patience=5,\n",
        "    restore_best_weights=True,\n",
        "    verbose=1\n",
        ")\n",
        "\n",
        "history = model.fit(html_train_dataset,\n",
        "                    validation_data=html_val_dataset,\n",
        "                    epochs=100,\n",
        "                    callbacks=[checkpoint_callback, early_stopping])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jYZf-vLqlaSa",
        "outputId": "1543eaa5-62ce-43b9-a28c-fb3607265cf0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"model_1\"\n",
            "__________________________________________________________________________________________________\n",
            " Layer (type)                Output Shape                 Param #   Connected to                  \n",
            "==================================================================================================\n",
            " input_3 (InputLayer)        [(None, 600, 3)]             0         []                            \n",
            "                                                                                                  \n",
            " input_2 (InputLayer)        [(None, 600, 600)]           0         []                            \n",
            "                                                                                                  \n",
            " gcn (GCN)                   (None, 600, 128)             512       ['input_3[0][0]',             \n",
            "                                                                     'input_2[0][0]']             \n",
            "                                                                                                  \n",
            " dropout_8 (Dropout)         (None, 600, 128)             0         ['gcn[0][0]']                 \n",
            "                                                                                                  \n",
            " gcn_1 (GCN)                 (None, 600, 128)             16512     ['dropout_8[0][0]',           \n",
            "                                                                     'input_2[0][0]']             \n",
            "                                                                                                  \n",
            " dropout_9 (Dropout)         (None, 600, 128)             0         ['gcn_1[0][0]']               \n",
            "                                                                                                  \n",
            " global_sum_pool (GlobalSum  (None, 128)                  0         ['dropout_9[0][0]']           \n",
            " Pool)                                                                                            \n",
            "                                                                                                  \n",
            " dense_7 (Dense)             (None, 128)                  16512     ['global_sum_pool[0][0]']     \n",
            "                                                                                                  \n",
            " dropout_10 (Dropout)        (None, 128)                  0         ['dense_7[0][0]']             \n",
            "                                                                                                  \n",
            " dense_8 (Dense)             (None, 64)                   8256      ['dropout_10[0][0]']          \n",
            "                                                                                                  \n",
            " dropout_11 (Dropout)        (None, 64)                   0         ['dense_8[0][0]']             \n",
            "                                                                                                  \n",
            " dense_9 (Dense)             (None, 1)                    65        ['dropout_11[0][0]']          \n",
            "                                                                                                  \n",
            "==================================================================================================\n",
            "Total params: 41857 (163.50 KB)\n",
            "Trainable params: 41857 (163.50 KB)\n",
            "Non-trainable params: 0 (0.00 Byte)\n",
            "__________________________________________________________________________________________________\n",
            "Epoch 1/100\n",
            "638/638 [==============================] - ETA: 0s - loss: 0.4801 - accuracy: 0.8642 - precision_1: 0.8291 - recall_1: 0.9175\n",
            "Epoch 1: val_loss improved from inf to 0.37772, saving model to models/best_html_model.keras\n",
            "638/638 [==============================] - 229s 356ms/step - loss: 0.4801 - accuracy: 0.8642 - precision_1: 0.8291 - recall_1: 0.9175 - val_loss: 0.3777 - val_accuracy: 0.8815 - val_precision_1: 0.8354 - val_recall_1: 0.9502\n",
            "Epoch 2/100\n",
            "638/638 [==============================] - ETA: 0s - loss: 0.3670 - accuracy: 0.8876 - precision_1: 0.8563 - recall_1: 0.9314\n",
            "Epoch 2: val_loss improved from 0.37772 to 0.35907, saving model to models/best_html_model.keras\n",
            "638/638 [==============================] - 216s 339ms/step - loss: 0.3670 - accuracy: 0.8876 - precision_1: 0.8563 - recall_1: 0.9314 - val_loss: 0.3591 - val_accuracy: 0.8841 - val_precision_1: 0.8416 - val_recall_1: 0.9463\n",
            "Epoch 3/100\n",
            "638/638 [==============================] - ETA: 0s - loss: 0.3400 - accuracy: 0.8909 - precision_1: 0.8651 - recall_1: 0.9262\n",
            "Epoch 3: val_loss improved from 0.35907 to 0.32743, saving model to models/best_html_model.keras\n",
            "638/638 [==============================] - 220s 345ms/step - loss: 0.3400 - accuracy: 0.8909 - precision_1: 0.8651 - recall_1: 0.9262 - val_loss: 0.3274 - val_accuracy: 0.8926 - val_precision_1: 0.8569 - val_recall_1: 0.9427\n",
            "Epoch 4/100\n",
            "638/638 [==============================] - ETA: 0s - loss: 0.3237 - accuracy: 0.8924 - precision_1: 0.8693 - recall_1: 0.9238\n",
            "Epoch 4: val_loss improved from 0.32743 to 0.31855, saving model to models/best_html_model.keras\n",
            "638/638 [==============================] - 218s 341ms/step - loss: 0.3237 - accuracy: 0.8924 - precision_1: 0.8693 - recall_1: 0.9238 - val_loss: 0.3186 - val_accuracy: 0.8935 - val_precision_1: 0.8598 - val_recall_1: 0.9404\n",
            "Epoch 5/100\n",
            "638/638 [==============================] - ETA: 0s - loss: 0.3090 - accuracy: 0.8943 - precision_1: 0.8742 - recall_1: 0.9211\n",
            "Epoch 5: val_loss improved from 0.31855 to 0.29552, saving model to models/best_html_model.keras\n",
            "638/638 [==============================] - 219s 343ms/step - loss: 0.3090 - accuracy: 0.8943 - precision_1: 0.8742 - recall_1: 0.9211 - val_loss: 0.2955 - val_accuracy: 0.8976 - val_precision_1: 0.8690 - val_recall_1: 0.9365\n",
            "Epoch 6/100\n",
            "638/638 [==============================] - ETA: 0s - loss: 0.2976 - accuracy: 0.8949 - precision_1: 0.8767 - recall_1: 0.9192\n",
            "Epoch 6: val_loss did not improve from 0.29552\n",
            "638/638 [==============================] - 214s 335ms/step - loss: 0.2976 - accuracy: 0.8949 - precision_1: 0.8767 - recall_1: 0.9192 - val_loss: 0.2973 - val_accuracy: 0.8978 - val_precision_1: 0.8705 - val_recall_1: 0.9347\n",
            "Epoch 7/100\n",
            "638/638 [==============================] - ETA: 0s - loss: 0.2866 - accuracy: 0.8965 - precision_1: 0.8804 - recall_1: 0.9177\n",
            "Epoch 7: val_loss improved from 0.29552 to 0.29453, saving model to models/best_html_model.keras\n",
            "638/638 [==============================] - 218s 341ms/step - loss: 0.2866 - accuracy: 0.8965 - precision_1: 0.8804 - recall_1: 0.9177 - val_loss: 0.2945 - val_accuracy: 0.8975 - val_precision_1: 0.8681 - val_recall_1: 0.9373\n",
            "Epoch 8/100\n",
            "638/638 [==============================] - ETA: 0s - loss: 0.2784 - accuracy: 0.8985 - precision_1: 0.8841 - recall_1: 0.9173\n",
            "Epoch 8: val_loss improved from 0.29453 to 0.28210, saving model to models/best_html_model.keras\n",
            "638/638 [==============================] - 220s 344ms/step - loss: 0.2784 - accuracy: 0.8985 - precision_1: 0.8841 - recall_1: 0.9173 - val_loss: 0.2821 - val_accuracy: 0.8992 - val_precision_1: 0.8726 - val_recall_1: 0.9349\n",
            "Epoch 9/100\n",
            "638/638 [==============================] - ETA: 0s - loss: 0.2720 - accuracy: 0.9005 - precision_1: 0.8858 - recall_1: 0.9196\n",
            "Epoch 9: val_loss improved from 0.28210 to 0.27589, saving model to models/best_html_model.keras\n",
            "638/638 [==============================] - 216s 338ms/step - loss: 0.2720 - accuracy: 0.9005 - precision_1: 0.8858 - recall_1: 0.9196 - val_loss: 0.2759 - val_accuracy: 0.9105 - val_precision_1: 0.8802 - val_recall_1: 0.9504\n",
            "Epoch 10/100\n",
            "638/638 [==============================] - ETA: 0s - loss: 0.2665 - accuracy: 0.9025 - precision_1: 0.8893 - recall_1: 0.9195\n",
            "Epoch 10: val_loss improved from 0.27589 to 0.25428, saving model to models/best_html_model.keras\n",
            "638/638 [==============================] - 219s 343ms/step - loss: 0.2665 - accuracy: 0.9025 - precision_1: 0.8893 - recall_1: 0.9195 - val_loss: 0.2543 - val_accuracy: 0.9110 - val_precision_1: 0.8919 - val_recall_1: 0.9353\n",
            "Epoch 11/100\n",
            "638/638 [==============================] - ETA: 0s - loss: 0.2619 - accuracy: 0.9034 - precision_1: 0.8897 - recall_1: 0.9211\n",
            "Epoch 11: val_loss did not improve from 0.25428\n",
            "638/638 [==============================] - 214s 336ms/step - loss: 0.2619 - accuracy: 0.9034 - precision_1: 0.8897 - recall_1: 0.9211 - val_loss: 0.2631 - val_accuracy: 0.9115 - val_precision_1: 0.8855 - val_recall_1: 0.9451\n",
            "Epoch 12/100\n",
            "638/638 [==============================] - ETA: 0s - loss: 0.2589 - accuracy: 0.9046 - precision_1: 0.8918 - recall_1: 0.9209\n",
            "Epoch 12: val_loss did not improve from 0.25428\n",
            "638/638 [==============================] - 219s 344ms/step - loss: 0.2589 - accuracy: 0.9046 - precision_1: 0.8918 - recall_1: 0.9209 - val_loss: 0.2627 - val_accuracy: 0.9130 - val_precision_1: 0.8859 - val_recall_1: 0.9482\n",
            "Epoch 13/100\n",
            "638/638 [==============================] - ETA: 0s - loss: 0.2537 - accuracy: 0.9066 - precision_1: 0.8956 - recall_1: 0.9204\n",
            "Epoch 13: val_loss improved from 0.25428 to 0.24608, saving model to models/best_html_model.keras\n",
            "638/638 [==============================] - 218s 342ms/step - loss: 0.2537 - accuracy: 0.9066 - precision_1: 0.8956 - recall_1: 0.9204 - val_loss: 0.2461 - val_accuracy: 0.9170 - val_precision_1: 0.8955 - val_recall_1: 0.9441\n",
            "Epoch 14/100\n",
            "638/638 [==============================] - ETA: 0s - loss: 0.2529 - accuracy: 0.9067 - precision_1: 0.8957 - recall_1: 0.9205\n",
            "Epoch 14: val_loss did not improve from 0.24608\n",
            "638/638 [==============================] - 219s 344ms/step - loss: 0.2529 - accuracy: 0.9067 - precision_1: 0.8957 - recall_1: 0.9205 - val_loss: 0.2653 - val_accuracy: 0.9164 - val_precision_1: 0.8930 - val_recall_1: 0.9461\n",
            "Epoch 15/100\n",
            "638/638 [==============================] - ETA: 0s - loss: 0.2499 - accuracy: 0.9081 - precision_1: 0.8970 - recall_1: 0.9220\n",
            "Epoch 15: val_loss did not improve from 0.24608\n",
            "638/638 [==============================] - 218s 342ms/step - loss: 0.2499 - accuracy: 0.9081 - precision_1: 0.8970 - recall_1: 0.9220 - val_loss: 0.2506 - val_accuracy: 0.9158 - val_precision_1: 0.8926 - val_recall_1: 0.9453\n",
            "Epoch 16/100\n",
            "638/638 [==============================] - ETA: 0s - loss: 0.2465 - accuracy: 0.9100 - precision_1: 0.8993 - recall_1: 0.9234\n",
            "Epoch 16: val_loss improved from 0.24608 to 0.23745, saving model to models/best_html_model.keras\n",
            "638/638 [==============================] - 218s 342ms/step - loss: 0.2465 - accuracy: 0.9100 - precision_1: 0.8993 - recall_1: 0.9234 - val_loss: 0.2374 - val_accuracy: 0.9166 - val_precision_1: 0.8956 - val_recall_1: 0.9431\n",
            "Epoch 17/100\n",
            "638/638 [==============================] - ETA: 0s - loss: 0.2439 - accuracy: 0.9100 - precision_1: 0.9006 - recall_1: 0.9217\n",
            "Epoch 17: val_loss improved from 0.23745 to 0.22794, saving model to models/best_html_model.keras\n",
            "638/638 [==============================] - 218s 341ms/step - loss: 0.2439 - accuracy: 0.9100 - precision_1: 0.9006 - recall_1: 0.9217 - val_loss: 0.2279 - val_accuracy: 0.9186 - val_precision_1: 0.9000 - val_recall_1: 0.9420\n",
            "Epoch 18/100\n",
            "638/638 [==============================] - ETA: 0s - loss: 0.2428 - accuracy: 0.9112 - precision_1: 0.9011 - recall_1: 0.9237\n",
            "Epoch 18: val_loss did not improve from 0.22794\n",
            "638/638 [==============================] - 219s 343ms/step - loss: 0.2428 - accuracy: 0.9112 - precision_1: 0.9011 - recall_1: 0.9237 - val_loss: 0.2327 - val_accuracy: 0.9197 - val_precision_1: 0.9020 - val_recall_1: 0.9418\n",
            "Epoch 19/100\n",
            "638/638 [==============================] - ETA: 0s - loss: 0.2412 - accuracy: 0.9121 - precision_1: 0.9023 - recall_1: 0.9243\n",
            "Epoch 19: val_loss did not improve from 0.22794\n",
            "638/638 [==============================] - 216s 339ms/step - loss: 0.2412 - accuracy: 0.9121 - precision_1: 0.9023 - recall_1: 0.9243 - val_loss: 0.2445 - val_accuracy: 0.9183 - val_precision_1: 0.8924 - val_recall_1: 0.9514\n",
            "Epoch 20/100\n",
            "638/638 [==============================] - ETA: 0s - loss: 0.2403 - accuracy: 0.9121 - precision_1: 0.9024 - recall_1: 0.9242\n",
            "Epoch 20: val_loss improved from 0.22794 to 0.22568, saving model to models/best_html_model.keras\n",
            "638/638 [==============================] - 216s 338ms/step - loss: 0.2403 - accuracy: 0.9121 - precision_1: 0.9024 - recall_1: 0.9242 - val_loss: 0.2257 - val_accuracy: 0.9213 - val_precision_1: 0.9039 - val_recall_1: 0.9427\n",
            "Epoch 21/100\n",
            "638/638 [==============================] - ETA: 0s - loss: 0.2406 - accuracy: 0.9118 - precision_1: 0.9022 - recall_1: 0.9238\n",
            "Epoch 21: val_loss did not improve from 0.22568\n",
            "638/638 [==============================] - 222s 347ms/step - loss: 0.2406 - accuracy: 0.9118 - precision_1: 0.9022 - recall_1: 0.9238 - val_loss: 0.2312 - val_accuracy: 0.9202 - val_precision_1: 0.8986 - val_recall_1: 0.9473\n",
            "Epoch 22/100\n",
            "638/638 [==============================] - ETA: 0s - loss: 0.2382 - accuracy: 0.9131 - precision_1: 0.9041 - recall_1: 0.9243\n",
            "Epoch 22: val_loss did not improve from 0.22568\n",
            "638/638 [==============================] - 221s 346ms/step - loss: 0.2382 - accuracy: 0.9131 - precision_1: 0.9041 - recall_1: 0.9243 - val_loss: 0.2300 - val_accuracy: 0.9208 - val_precision_1: 0.9004 - val_recall_1: 0.9463\n",
            "Epoch 23/100\n",
            "638/638 [==============================] - ETA: 0s - loss: 0.2366 - accuracy: 0.9131 - precision_1: 0.9047 - recall_1: 0.9235\n",
            "Epoch 23: val_loss improved from 0.22568 to 0.22387, saving model to models/best_html_model.keras\n",
            "638/638 [==============================] - 221s 346ms/step - loss: 0.2366 - accuracy: 0.9131 - precision_1: 0.9047 - recall_1: 0.9235 - val_loss: 0.2239 - val_accuracy: 0.9201 - val_precision_1: 0.8986 - val_recall_1: 0.9471\n",
            "Epoch 24/100\n",
            "638/638 [==============================] - ETA: 0s - loss: 0.2362 - accuracy: 0.9140 - precision_1: 0.9046 - recall_1: 0.9257\n",
            "Epoch 24: val_loss did not improve from 0.22387\n",
            "638/638 [==============================] - 221s 346ms/step - loss: 0.2362 - accuracy: 0.9140 - precision_1: 0.9046 - recall_1: 0.9257 - val_loss: 0.2276 - val_accuracy: 0.9207 - val_precision_1: 0.8990 - val_recall_1: 0.9478\n",
            "Epoch 25/100\n",
            "638/638 [==============================] - ETA: 0s - loss: 0.2345 - accuracy: 0.9139 - precision_1: 0.9046 - recall_1: 0.9254\n",
            "Epoch 25: val_loss improved from 0.22387 to 0.21964, saving model to models/best_html_model.keras\n",
            "638/638 [==============================] - 218s 341ms/step - loss: 0.2345 - accuracy: 0.9139 - precision_1: 0.9046 - recall_1: 0.9254 - val_loss: 0.2196 - val_accuracy: 0.9218 - val_precision_1: 0.9018 - val_recall_1: 0.9467\n",
            "Epoch 26/100\n",
            "638/638 [==============================] - ETA: 0s - loss: 0.2335 - accuracy: 0.9142 - precision_1: 0.9063 - recall_1: 0.9238\n",
            "Epoch 26: val_loss improved from 0.21964 to 0.21619, saving model to models/best_html_model.keras\n",
            "638/638 [==============================] - 215s 337ms/step - loss: 0.2335 - accuracy: 0.9142 - precision_1: 0.9063 - recall_1: 0.9238 - val_loss: 0.2162 - val_accuracy: 0.9232 - val_precision_1: 0.9046 - val_recall_1: 0.9463\n",
            "Epoch 27/100\n",
            "638/638 [==============================] - ETA: 0s - loss: 0.2319 - accuracy: 0.9150 - precision_1: 0.9076 - recall_1: 0.9242\n",
            "Epoch 27: val_loss did not improve from 0.21619\n",
            "638/638 [==============================] - 218s 342ms/step - loss: 0.2319 - accuracy: 0.9150 - precision_1: 0.9076 - recall_1: 0.9242 - val_loss: 0.2235 - val_accuracy: 0.9205 - val_precision_1: 0.9014 - val_recall_1: 0.9443\n",
            "Epoch 28/100\n",
            "638/638 [==============================] - ETA: 0s - loss: 0.2319 - accuracy: 0.9145 - precision_1: 0.9075 - recall_1: 0.9231\n",
            "Epoch 28: val_loss did not improve from 0.21619\n",
            "638/638 [==============================] - 216s 339ms/step - loss: 0.2319 - accuracy: 0.9145 - precision_1: 0.9075 - recall_1: 0.9231 - val_loss: 0.2201 - val_accuracy: 0.9209 - val_precision_1: 0.9014 - val_recall_1: 0.9451\n",
            "Epoch 29/100\n",
            "638/638 [==============================] - ETA: 0s - loss: 0.2329 - accuracy: 0.9141 - precision_1: 0.9071 - recall_1: 0.9226\n",
            "Epoch 29: val_loss did not improve from 0.21619\n",
            "638/638 [==============================] - 217s 341ms/step - loss: 0.2329 - accuracy: 0.9141 - precision_1: 0.9071 - recall_1: 0.9226 - val_loss: 0.2203 - val_accuracy: 0.9206 - val_precision_1: 0.8991 - val_recall_1: 0.9475\n",
            "Epoch 30/100\n",
            "638/638 [==============================] - ETA: 0s - loss: 0.2306 - accuracy: 0.9159 - precision_1: 0.9088 - recall_1: 0.9245\n",
            "Epoch 30: val_loss improved from 0.21619 to 0.20983, saving model to models/best_html_model.keras\n",
            "638/638 [==============================] - 219s 343ms/step - loss: 0.2306 - accuracy: 0.9159 - precision_1: 0.9088 - recall_1: 0.9245 - val_loss: 0.2098 - val_accuracy: 0.9239 - val_precision_1: 0.9129 - val_recall_1: 0.9373\n",
            "Epoch 31/100\n",
            "638/638 [==============================] - ETA: 0s - loss: 0.2299 - accuracy: 0.9161 - precision_1: 0.9097 - recall_1: 0.9240\n",
            "Epoch 31: val_loss did not improve from 0.20983\n",
            "638/638 [==============================] - 218s 341ms/step - loss: 0.2299 - accuracy: 0.9161 - precision_1: 0.9097 - recall_1: 0.9240 - val_loss: 0.2206 - val_accuracy: 0.9232 - val_precision_1: 0.9090 - val_recall_1: 0.9406\n",
            "Epoch 32/100\n",
            "638/638 [==============================] - ETA: 0s - loss: 0.2306 - accuracy: 0.9163 - precision_1: 0.9104 - recall_1: 0.9235\n",
            "Epoch 32: val_loss did not improve from 0.20983\n",
            "638/638 [==============================] - 218s 341ms/step - loss: 0.2306 - accuracy: 0.9163 - precision_1: 0.9104 - recall_1: 0.9235 - val_loss: 0.2146 - val_accuracy: 0.9232 - val_precision_1: 0.9070 - val_recall_1: 0.9431\n",
            "Epoch 33/100\n",
            "638/638 [==============================] - ETA: 0s - loss: 0.2281 - accuracy: 0.9161 - precision_1: 0.9103 - recall_1: 0.9231\n",
            "Epoch 33: val_loss did not improve from 0.20983\n",
            "638/638 [==============================] - 217s 341ms/step - loss: 0.2281 - accuracy: 0.9161 - precision_1: 0.9103 - recall_1: 0.9231 - val_loss: 0.2152 - val_accuracy: 0.9231 - val_precision_1: 0.9020 - val_recall_1: 0.9494\n",
            "Epoch 34/100\n",
            "638/638 [==============================] - ETA: 0s - loss: 0.2309 - accuracy: 0.9154 - precision_1: 0.9086 - recall_1: 0.9237\n",
            "Epoch 34: val_loss did not improve from 0.20983\n",
            "638/638 [==============================] - 220s 345ms/step - loss: 0.2309 - accuracy: 0.9154 - precision_1: 0.9086 - recall_1: 0.9237 - val_loss: 0.2118 - val_accuracy: 0.9245 - val_precision_1: 0.9110 - val_recall_1: 0.9410\n",
            "Epoch 35/100\n",
            "638/638 [==============================] - ETA: 0s - loss: 0.2280 - accuracy: 0.9165 - precision_1: 0.9110 - recall_1: 0.9232\n",
            "Epoch 35: val_loss did not improve from 0.20983\n",
            "Restoring model weights from the end of the best epoch: 30.\n",
            "638/638 [==============================] - 217s 340ms/step - loss: 0.2280 - accuracy: 0.9165 - precision_1: 0.9110 - recall_1: 0.9232 - val_loss: 0.2126 - val_accuracy: 0.9228 - val_precision_1: 0.9032 - val_recall_1: 0.9473\n",
            "Epoch 35: early stopping\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pon8ohwipVJt"
      },
      "source": [
        "#### Evaluate model"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "best_html_model = keras.models.load_model(\n",
        "    'models/best_html_model.keras',\n",
        "    custom_objects={'GCNConv': GCNConv,\n",
        "                    'GlobalSumPool': GlobalSumPool,\n",
        "                    'GCN': GCN})"
      ],
      "metadata": {
        "id": "cVd_waKNmomo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "results = best_html_model.evaluate(html_test_dataset, verbose=1)\n",
        "precision = results[2]\n",
        "recall = results[3]\n",
        "f1_score = 2 * (precision * recall) / (precision + recall)\n",
        "print(f\"F1-Score: {f1_score:.4f}\")"
      ],
      "metadata": {
        "id": "7KqKAqXRm8gS",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b50e1538-f2a8-4c65-bd77-c856a20b94d7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "80/80 [==============================] - 22s 150ms/step - loss: 0.2193 - accuracy: 0.9174 - precision_1: 0.9119 - recall_1: 0.9239\n",
            "F1-Score: 0.9179\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Experiment 1**"
      ],
      "metadata": {
        "id": "zfHZ-Dv1ltEQ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Train model"
      ],
      "metadata": {
        "id": "egRGVWnlmkMs"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model = create_html_model(max_nodes=max_nodes,\n",
        "                          feature_dim=feature_dim,\n",
        "                          gcn_units=128,\n",
        "                          num_gcn_layers=1,\n",
        "                          dropout=0.3,\n",
        "                          dense_dim=128,\n",
        "                          l2_reg=5e-4)\n",
        "\n",
        "model.summary()\n",
        "\n",
        "optimizer = keras.optimizers.Adam(learning_rate=1e-3)\n",
        "metrics = ['accuracy', tf.keras.metrics.Precision(), tf.keras.metrics.Recall()]\n",
        "model.compile(optimizer=optimizer, loss='binary_crossentropy', metrics=metrics)\n",
        "\n",
        "checkpoint_filepath = 'models/best_html_model1.keras'\n",
        "\n",
        "checkpoint_callback = tf.keras.callbacks.ModelCheckpoint(\n",
        "    filepath=checkpoint_filepath,\n",
        "    save_weights_only=False,\n",
        "    monitor='val_loss',\n",
        "    mode='min',\n",
        "    save_best_only=True,\n",
        "    verbose=1\n",
        ")\n",
        "\n",
        "early_stopping = tf.keras.callbacks.EarlyStopping(\n",
        "    monitor='val_loss',\n",
        "    patience=5,\n",
        "    restore_best_weights=True,\n",
        "    verbose=1\n",
        ")\n",
        "\n",
        "history = model.fit(html_train_dataset,\n",
        "                    validation_data=html_val_dataset,\n",
        "                    epochs=100,\n",
        "                    callbacks=[checkpoint_callback, early_stopping])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HiVOQgWOmivM",
        "outputId": "40baa92a-5eec-4581-a89f-79739ff5e2c0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"model\"\n",
            "__________________________________________________________________________________________________\n",
            " Layer (type)                Output Shape                 Param #   Connected to                  \n",
            "==================================================================================================\n",
            " input_2 (InputLayer)        [(None, 600, 3)]             0         []                            \n",
            "                                                                                                  \n",
            " input_1 (InputLayer)        [(None, 600, 600)]           0         []                            \n",
            "                                                                                                  \n",
            " gcn (GCN)                   (None, 600, 128)             512       ['input_2[0][0]',             \n",
            "                                                                     'input_1[0][0]']             \n",
            "                                                                                                  \n",
            " dropout (Dropout)           (None, 600, 128)             0         ['gcn[0][0]']                 \n",
            "                                                                                                  \n",
            " global_sum_pool (GlobalSum  (None, 128)                  0         ['dropout[0][0]']             \n",
            " Pool)                                                                                            \n",
            "                                                                                                  \n",
            " dense (Dense)               (None, 128)                  16512     ['global_sum_pool[0][0]']     \n",
            "                                                                                                  \n",
            " dropout_1 (Dropout)         (None, 128)                  0         ['dense[0][0]']               \n",
            "                                                                                                  \n",
            " dense_1 (Dense)             (None, 64)                   8256      ['dropout_1[0][0]']           \n",
            "                                                                                                  \n",
            " dropout_2 (Dropout)         (None, 64)                   0         ['dense_1[0][0]']             \n",
            "                                                                                                  \n",
            " dense_2 (Dense)             (None, 1)                    65        ['dropout_2[0][0]']           \n",
            "                                                                                                  \n",
            "==================================================================================================\n",
            "Total params: 25345 (99.00 KB)\n",
            "Trainable params: 25345 (99.00 KB)\n",
            "Non-trainable params: 0 (0.00 Byte)\n",
            "__________________________________________________________________________________________________\n",
            "Epoch 1/100\n",
            "638/638 [==============================] - ETA: 0s - loss: 0.4605 - accuracy: 0.8612 - precision: 0.8263 - recall: 0.9148\n",
            "Epoch 1: val_loss improved from inf to 0.35928, saving model to models/best_html_model1.keras\n",
            "638/638 [==============================] - 146s 227ms/step - loss: 0.4605 - accuracy: 0.8612 - precision: 0.8263 - recall: 0.9148 - val_loss: 0.3593 - val_accuracy: 0.8810 - val_precision: 0.8371 - val_recall: 0.9461\n",
            "Epoch 2/100\n",
            "638/638 [==============================] - ETA: 0s - loss: 0.3666 - accuracy: 0.8839 - precision: 0.8515 - recall: 0.9299\n",
            "Epoch 2: val_loss improved from 0.35928 to 0.35525, saving model to models/best_html_model1.keras\n",
            "638/638 [==============================] - 134s 210ms/step - loss: 0.3666 - accuracy: 0.8839 - precision: 0.8515 - recall: 0.9299 - val_loss: 0.3552 - val_accuracy: 0.8801 - val_precision: 0.8342 - val_recall: 0.9488\n",
            "Epoch 3/100\n",
            "638/638 [==============================] - ETA: 0s - loss: 0.3462 - accuracy: 0.8875 - precision: 0.8584 - recall: 0.9281\n",
            "Epoch 3: val_loss improved from 0.35525 to 0.33372, saving model to models/best_html_model1.keras\n",
            "638/638 [==============================] - 134s 210ms/step - loss: 0.3462 - accuracy: 0.8875 - precision: 0.8584 - recall: 0.9281 - val_loss: 0.3337 - val_accuracy: 0.8868 - val_precision: 0.8476 - val_recall: 0.9431\n",
            "Epoch 4/100\n",
            "638/638 [==============================] - ETA: 0s - loss: 0.3319 - accuracy: 0.8883 - precision: 0.8614 - recall: 0.9255\n",
            "Epoch 4: val_loss improved from 0.33372 to 0.32999, saving model to models/best_html_model1.keras\n",
            "638/638 [==============================] - 135s 211ms/step - loss: 0.3319 - accuracy: 0.8883 - precision: 0.8614 - recall: 0.9255 - val_loss: 0.3300 - val_accuracy: 0.8884 - val_precision: 0.8507 - val_recall: 0.9422\n",
            "Epoch 5/100\n",
            "638/638 [==============================] - ETA: 0s - loss: 0.3200 - accuracy: 0.8891 - precision: 0.8641 - recall: 0.9234\n",
            "Epoch 5: val_loss improved from 0.32999 to 0.32481, saving model to models/best_html_model1.keras\n",
            "638/638 [==============================] - 135s 211ms/step - loss: 0.3200 - accuracy: 0.8891 - precision: 0.8641 - recall: 0.9234 - val_loss: 0.3248 - val_accuracy: 0.8867 - val_precision: 0.8476 - val_recall: 0.9429\n",
            "Epoch 6/100\n",
            "638/638 [==============================] - ETA: 0s - loss: 0.3112 - accuracy: 0.8902 - precision: 0.8666 - recall: 0.9224\n",
            "Epoch 6: val_loss improved from 0.32481 to 0.30299, saving model to models/best_html_model1.keras\n",
            "638/638 [==============================] - 134s 210ms/step - loss: 0.3112 - accuracy: 0.8902 - precision: 0.8666 - recall: 0.9224 - val_loss: 0.3030 - val_accuracy: 0.8917 - val_precision: 0.8583 - val_recall: 0.9382\n",
            "Epoch 7/100\n",
            "638/638 [==============================] - ETA: 0s - loss: 0.3031 - accuracy: 0.8915 - precision: 0.8696 - recall: 0.9211\n",
            "Epoch 7: val_loss improved from 0.30299 to 0.30137, saving model to models/best_html_model1.keras\n",
            "638/638 [==============================] - 133s 208ms/step - loss: 0.3031 - accuracy: 0.8915 - precision: 0.8696 - recall: 0.9211 - val_loss: 0.3014 - val_accuracy: 0.8941 - val_precision: 0.8615 - val_recall: 0.9392\n",
            "Epoch 8/100\n",
            "638/638 [==============================] - ETA: 0s - loss: 0.2963 - accuracy: 0.8925 - precision: 0.8715 - recall: 0.9207\n",
            "Epoch 8: val_loss improved from 0.30137 to 0.29237, saving model to models/best_html_model1.keras\n",
            "638/638 [==============================] - 134s 210ms/step - loss: 0.2963 - accuracy: 0.8925 - precision: 0.8715 - recall: 0.9207 - val_loss: 0.2924 - val_accuracy: 0.8940 - val_precision: 0.8624 - val_recall: 0.9376\n",
            "Epoch 9/100\n",
            "638/638 [==============================] - ETA: 0s - loss: 0.2911 - accuracy: 0.8933 - precision: 0.8729 - recall: 0.9206\n",
            "Epoch 9: val_loss improved from 0.29237 to 0.28363, saving model to models/best_html_model1.keras\n",
            "638/638 [==============================] - 132s 207ms/step - loss: 0.2911 - accuracy: 0.8933 - precision: 0.8729 - recall: 0.9206 - val_loss: 0.2836 - val_accuracy: 0.8954 - val_precision: 0.8639 - val_recall: 0.9386\n",
            "Epoch 10/100\n",
            "638/638 [==============================] - ETA: 0s - loss: 0.2869 - accuracy: 0.8950 - precision: 0.8753 - recall: 0.9213\n",
            "Epoch 10: val_loss improved from 0.28363 to 0.28190, saving model to models/best_html_model1.keras\n",
            "638/638 [==============================] - 133s 209ms/step - loss: 0.2869 - accuracy: 0.8950 - precision: 0.8753 - recall: 0.9213 - val_loss: 0.2819 - val_accuracy: 0.8987 - val_precision: 0.8773 - val_recall: 0.9271\n",
            "Epoch 11/100\n",
            "638/638 [==============================] - ETA: 0s - loss: 0.2829 - accuracy: 0.8970 - precision: 0.8780 - recall: 0.9223\n",
            "Epoch 11: val_loss improved from 0.28190 to 0.27653, saving model to models/best_html_model1.keras\n",
            "638/638 [==============================] - 133s 208ms/step - loss: 0.2829 - accuracy: 0.8970 - precision: 0.8780 - recall: 0.9223 - val_loss: 0.2765 - val_accuracy: 0.8983 - val_precision: 0.8723 - val_recall: 0.9333\n",
            "Epoch 12/100\n",
            "638/638 [==============================] - ETA: 0s - loss: 0.2807 - accuracy: 0.8979 - precision: 0.8789 - recall: 0.9230\n",
            "Epoch 12: val_loss improved from 0.27653 to 0.27280, saving model to models/best_html_model1.keras\n",
            "638/638 [==============================] - 134s 210ms/step - loss: 0.2807 - accuracy: 0.8979 - precision: 0.8789 - recall: 0.9230 - val_loss: 0.2728 - val_accuracy: 0.9000 - val_precision: 0.8792 - val_recall: 0.9275\n",
            "Epoch 13/100\n",
            "638/638 [==============================] - ETA: 0s - loss: 0.2782 - accuracy: 0.9000 - precision: 0.8804 - recall: 0.9258\n",
            "Epoch 13: val_loss improved from 0.27280 to 0.26369, saving model to models/best_html_model1.keras\n",
            "638/638 [==============================] - 132s 207ms/step - loss: 0.2782 - accuracy: 0.9000 - precision: 0.8804 - recall: 0.9258 - val_loss: 0.2637 - val_accuracy: 0.9026 - val_precision: 0.8828 - val_recall: 0.9286\n",
            "Epoch 14/100\n",
            "638/638 [==============================] - ETA: 0s - loss: 0.2745 - accuracy: 0.9016 - precision: 0.8820 - recall: 0.9273\n",
            "Epoch 14: val_loss did not improve from 0.26369\n",
            "638/638 [==============================] - 133s 209ms/step - loss: 0.2745 - accuracy: 0.9016 - precision: 0.8820 - recall: 0.9273 - val_loss: 0.2649 - val_accuracy: 0.9024 - val_precision: 0.8833 - val_recall: 0.9273\n",
            "Epoch 15/100\n",
            "638/638 [==============================] - ETA: 0s - loss: 0.2729 - accuracy: 0.9021 - precision: 0.8824 - recall: 0.9279\n",
            "Epoch 15: val_loss did not improve from 0.26369\n",
            "638/638 [==============================] - 133s 209ms/step - loss: 0.2729 - accuracy: 0.9021 - precision: 0.8824 - recall: 0.9279 - val_loss: 0.2653 - val_accuracy: 0.9024 - val_precision: 0.8826 - val_recall: 0.9282\n",
            "Epoch 16/100\n",
            "638/638 [==============================] - ETA: 0s - loss: 0.2708 - accuracy: 0.9027 - precision: 0.8837 - recall: 0.9275\n",
            "Epoch 16: val_loss improved from 0.26369 to 0.26215, saving model to models/best_html_model1.keras\n",
            "638/638 [==============================] - 133s 208ms/step - loss: 0.2708 - accuracy: 0.9027 - precision: 0.8837 - recall: 0.9275 - val_loss: 0.2622 - val_accuracy: 0.9027 - val_precision: 0.8819 - val_recall: 0.9300\n",
            "Epoch 17/100\n",
            "638/638 [==============================] - ETA: 0s - loss: 0.2690 - accuracy: 0.9036 - precision: 0.8855 - recall: 0.9270\n",
            "Epoch 17: val_loss improved from 0.26215 to 0.25895, saving model to models/best_html_model1.keras\n",
            "638/638 [==============================] - 132s 207ms/step - loss: 0.2690 - accuracy: 0.9036 - precision: 0.8855 - recall: 0.9270 - val_loss: 0.2589 - val_accuracy: 0.9121 - val_precision: 0.8860 - val_recall: 0.9459\n",
            "Epoch 18/100\n",
            "638/638 [==============================] - ETA: 0s - loss: 0.2689 - accuracy: 0.9034 - precision: 0.8852 - recall: 0.9270\n",
            "Epoch 18: val_loss did not improve from 0.25895\n",
            "638/638 [==============================] - 133s 208ms/step - loss: 0.2689 - accuracy: 0.9034 - precision: 0.8852 - recall: 0.9270 - val_loss: 0.2591 - val_accuracy: 0.9097 - val_precision: 0.8854 - val_recall: 0.9412\n",
            "Epoch 19/100\n",
            "638/638 [==============================] - ETA: 0s - loss: 0.2671 - accuracy: 0.9037 - precision: 0.8859 - recall: 0.9268\n",
            "Epoch 19: val_loss improved from 0.25895 to 0.25581, saving model to models/best_html_model1.keras\n",
            "638/638 [==============================] - 134s 210ms/step - loss: 0.2671 - accuracy: 0.9037 - precision: 0.8859 - recall: 0.9268 - val_loss: 0.2558 - val_accuracy: 0.9133 - val_precision: 0.8895 - val_recall: 0.9439\n",
            "Epoch 20/100\n",
            "638/638 [==============================] - ETA: 0s - loss: 0.2652 - accuracy: 0.9047 - precision: 0.8875 - recall: 0.9268\n",
            "Epoch 20: val_loss improved from 0.25581 to 0.25566, saving model to models/best_html_model1.keras\n",
            "638/638 [==============================] - 134s 210ms/step - loss: 0.2652 - accuracy: 0.9047 - precision: 0.8875 - recall: 0.9268 - val_loss: 0.2557 - val_accuracy: 0.9107 - val_precision: 0.8858 - val_recall: 0.9429\n",
            "Epoch 21/100\n",
            "638/638 [==============================] - ETA: 0s - loss: 0.2652 - accuracy: 0.9054 - precision: 0.8888 - recall: 0.9268\n",
            "Epoch 21: val_loss improved from 0.25566 to 0.24537, saving model to models/best_html_model1.keras\n",
            "638/638 [==============================] - 134s 210ms/step - loss: 0.2652 - accuracy: 0.9054 - precision: 0.8888 - recall: 0.9268 - val_loss: 0.2454 - val_accuracy: 0.9164 - val_precision: 0.9006 - val_recall: 0.9361\n",
            "Epoch 22/100\n",
            "638/638 [==============================] - ETA: 0s - loss: 0.2635 - accuracy: 0.9059 - precision: 0.8888 - recall: 0.9279\n",
            "Epoch 22: val_loss did not improve from 0.24537\n",
            "638/638 [==============================] - 133s 209ms/step - loss: 0.2635 - accuracy: 0.9059 - precision: 0.8888 - recall: 0.9279 - val_loss: 0.2546 - val_accuracy: 0.9137 - val_precision: 0.8897 - val_recall: 0.9445\n",
            "Epoch 23/100\n",
            "638/638 [==============================] - ETA: 0s - loss: 0.2623 - accuracy: 0.9074 - precision: 0.8897 - recall: 0.9300\n",
            "Epoch 23: val_loss did not improve from 0.24537\n",
            "638/638 [==============================] - 132s 206ms/step - loss: 0.2623 - accuracy: 0.9074 - precision: 0.8897 - recall: 0.9300 - val_loss: 0.2605 - val_accuracy: 0.9129 - val_precision: 0.8876 - val_recall: 0.9457\n",
            "Epoch 24/100\n",
            "638/638 [==============================] - ETA: 0s - loss: 0.2611 - accuracy: 0.9071 - precision: 0.8899 - recall: 0.9291\n",
            "Epoch 24: val_loss did not improve from 0.24537\n",
            "638/638 [==============================] - 133s 208ms/step - loss: 0.2611 - accuracy: 0.9071 - precision: 0.8899 - recall: 0.9291 - val_loss: 0.2605 - val_accuracy: 0.9134 - val_precision: 0.8867 - val_recall: 0.9480\n",
            "Epoch 25/100\n",
            "638/638 [==============================] - ETA: 0s - loss: 0.2607 - accuracy: 0.9070 - precision: 0.8904 - recall: 0.9283\n",
            "Epoch 25: val_loss did not improve from 0.24537\n",
            "638/638 [==============================] - 133s 208ms/step - loss: 0.2607 - accuracy: 0.9070 - precision: 0.8904 - recall: 0.9283 - val_loss: 0.2586 - val_accuracy: 0.9123 - val_precision: 0.8873 - val_recall: 0.9445\n",
            "Epoch 26/100\n",
            "638/638 [==============================] - ETA: 0s - loss: 0.2598 - accuracy: 0.9078 - precision: 0.8912 - recall: 0.9290\n",
            "Epoch 26: val_loss improved from 0.24537 to 0.24410, saving model to models/best_html_model1.keras\n",
            "638/638 [==============================] - 133s 208ms/step - loss: 0.2598 - accuracy: 0.9078 - precision: 0.8912 - recall: 0.9290 - val_loss: 0.2441 - val_accuracy: 0.9137 - val_precision: 0.8884 - val_recall: 0.9463\n",
            "Epoch 27/100\n",
            "638/638 [==============================] - ETA: 0s - loss: 0.2588 - accuracy: 0.9077 - precision: 0.8912 - recall: 0.9288\n",
            "Epoch 27: val_loss did not improve from 0.24410\n",
            "638/638 [==============================] - 132s 207ms/step - loss: 0.2588 - accuracy: 0.9077 - precision: 0.8912 - recall: 0.9288 - val_loss: 0.2488 - val_accuracy: 0.9146 - val_precision: 0.8901 - val_recall: 0.9461\n",
            "Epoch 28/100\n",
            "638/638 [==============================] - ETA: 0s - loss: 0.2586 - accuracy: 0.9073 - precision: 0.8912 - recall: 0.9278\n",
            "Epoch 28: val_loss did not improve from 0.24410\n",
            "638/638 [==============================] - 133s 208ms/step - loss: 0.2586 - accuracy: 0.9073 - precision: 0.8912 - recall: 0.9278 - val_loss: 0.2478 - val_accuracy: 0.9148 - val_precision: 0.8875 - val_recall: 0.9500\n",
            "Epoch 29/100\n",
            "638/638 [==============================] - ETA: 0s - loss: 0.2581 - accuracy: 0.9076 - precision: 0.8914 - recall: 0.9284\n",
            "Epoch 29: val_loss did not improve from 0.24410\n",
            "638/638 [==============================] - 133s 208ms/step - loss: 0.2581 - accuracy: 0.9076 - precision: 0.8914 - recall: 0.9284 - val_loss: 0.2505 - val_accuracy: 0.9144 - val_precision: 0.8866 - val_recall: 0.9504\n",
            "Epoch 30/100\n",
            "638/638 [==============================] - ETA: 0s - loss: 0.2596 - accuracy: 0.9078 - precision: 0.8910 - recall: 0.9293\n",
            "Epoch 30: val_loss did not improve from 0.24410\n",
            "638/638 [==============================] - 132s 207ms/step - loss: 0.2596 - accuracy: 0.9078 - precision: 0.8910 - recall: 0.9293 - val_loss: 0.2481 - val_accuracy: 0.9139 - val_precision: 0.8893 - val_recall: 0.9455\n",
            "Epoch 31/100\n",
            "638/638 [==============================] - ETA: 0s - loss: 0.2578 - accuracy: 0.9089 - precision: 0.8922 - recall: 0.9301\n",
            "Epoch 31: val_loss did not improve from 0.24410\n",
            "Restoring model weights from the end of the best epoch: 26.\n",
            "638/638 [==============================] - 132s 208ms/step - loss: 0.2578 - accuracy: 0.9089 - precision: 0.8922 - recall: 0.9301 - val_loss: 0.2445 - val_accuracy: 0.9150 - val_precision: 0.8911 - val_recall: 0.9455\n",
            "Epoch 31: early stopping\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Evaluate model"
      ],
      "metadata": {
        "id": "Cq8nEW8hmuab"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "best_html_model1 = keras.models.load_model(\n",
        "    'models/best_html_model1.keras',\n",
        "    custom_objects={'GCNConv': GCNConv,\n",
        "                    'GlobalSumPool': GlobalSumPool,\n",
        "                    'GCN': GCN})"
      ],
      "metadata": {
        "id": "m40q8blCmpTJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "results = best_html_model1.evaluate(html_test_dataset, verbose=1)\n",
        "precision = results[2]\n",
        "recall = results[3]\n",
        "f1_score = 2 * (precision * recall) / (precision + recall)\n",
        "print(f\"F1-Score: {f1_score:.4f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "umlT_wttmt5M",
        "outputId": "17e266d7-ad08-4a88-f8ea-bc4d6d3ed31a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "80/80 [==============================] - 18s 100ms/step - loss: 0.2501 - accuracy: 0.9105 - precision: 0.8895 - recall: 0.9375\n",
            "F1-Score: 0.9128\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Experiment 2**"
      ],
      "metadata": {
        "id": "8tXieaPfp4oH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def create_html_model(max_nodes, feature_dim, gcn_units, dropout=0.1,\n",
        "                      num_gcn_layers=1, dense_dim=128, l2_reg=5e-4):\n",
        "    inputs_adj = keras.Input(shape=(max_nodes, max_nodes), dtype=tf.float32)\n",
        "    inputs_feat = keras.Input(shape=(max_nodes, feature_dim), dtype=tf.float32)\n",
        "\n",
        "    x = inputs_feat\n",
        "    for _ in range(num_gcn_layers):\n",
        "        x = GCN(gcn_units, activation='relu')([x, inputs_adj])\n",
        "        x = layers.Dropout(dropout)(x)\n",
        "    x = GlobalSumPool()(x)\n",
        "    x = layers.Dense(dense_dim,\n",
        "                     activation='relu',\n",
        "                     kernel_regularizer=regularizers.l2(l2_reg))(x)\n",
        "    x = layers.Dropout(dropout)(x)\n",
        "    outputs = layers.Dense(1, activation='sigmoid')(x)\n",
        "    html_model = keras.Model(inputs=[inputs_adj, inputs_feat], outputs=outputs)\n",
        "\n",
        "    return html_model"
      ],
      "metadata": {
        "id": "NnQENm5Mp2gL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = create_html_model(max_nodes=max_nodes,\n",
        "                          feature_dim=feature_dim,\n",
        "                          gcn_units=128,\n",
        "                          num_gcn_layers=2,\n",
        "                          dropout=0.3,\n",
        "                          dense_dim=128,\n",
        "                          l2_reg=5e-4)\n",
        "\n",
        "model.summary()\n",
        "\n",
        "optimizer = keras.optimizers.Adam(learning_rate=1e-3)\n",
        "metrics = ['accuracy', tf.keras.metrics.Precision(), tf.keras.metrics.Recall()]\n",
        "model.compile(optimizer=optimizer, loss='binary_crossentropy', metrics=metrics)\n",
        "\n",
        "checkpoint_filepath = 'models/best_html_model2.keras'\n",
        "\n",
        "checkpoint_callback = tf.keras.callbacks.ModelCheckpoint(\n",
        "    filepath=checkpoint_filepath,\n",
        "    save_weights_only=False,\n",
        "    monitor='val_loss',\n",
        "    mode='min',\n",
        "    save_best_only=True,\n",
        "    verbose=1\n",
        ")\n",
        "\n",
        "early_stopping = tf.keras.callbacks.EarlyStopping(\n",
        "    monitor='val_loss',\n",
        "    patience=5,\n",
        "    restore_best_weights=True,\n",
        "    verbose=1\n",
        ")\n",
        "\n",
        "history = model.fit(html_train_dataset,\n",
        "                    validation_data=html_val_dataset,\n",
        "                    epochs=100,\n",
        "                    callbacks=[checkpoint_callback, early_stopping])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bLoGIp7ZqPnV",
        "outputId": "907d3306-2a8f-4346-e93f-add52b29b00a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"model_2\"\n",
            "__________________________________________________________________________________________________\n",
            " Layer (type)                Output Shape                 Param #   Connected to                  \n",
            "==================================================================================================\n",
            " input_6 (InputLayer)        [(None, 600, 3)]             0         []                            \n",
            "                                                                                                  \n",
            " input_5 (InputLayer)        [(None, 600, 600)]           0         []                            \n",
            "                                                                                                  \n",
            " gcn_4 (GCN)                 (None, 600, 128)             512       ['input_6[0][0]',             \n",
            "                                                                     'input_5[0][0]']             \n",
            "                                                                                                  \n",
            " dropout_6 (Dropout)         (None, 600, 128)             0         ['gcn_4[0][0]']               \n",
            "                                                                                                  \n",
            " gcn_5 (GCN)                 (None, 600, 128)             16512     ['dropout_6[0][0]',           \n",
            "                                                                     'input_5[0][0]']             \n",
            "                                                                                                  \n",
            " dropout_7 (Dropout)         (None, 600, 128)             0         ['gcn_5[0][0]']               \n",
            "                                                                                                  \n",
            " global_sum_pool_2 (GlobalS  (None, 128)                  0         ['dropout_7[0][0]']           \n",
            " umPool)                                                                                          \n",
            "                                                                                                  \n",
            " dense_5 (Dense)             (None, 128)                  16512     ['global_sum_pool_2[0][0]']   \n",
            "                                                                                                  \n",
            " dropout_8 (Dropout)         (None, 128)                  0         ['dense_5[0][0]']             \n",
            "                                                                                                  \n",
            " dense_6 (Dense)             (None, 1)                    129       ['dropout_8[0][0]']           \n",
            "                                                                                                  \n",
            "==================================================================================================\n",
            "Total params: 33665 (131.50 KB)\n",
            "Trainable params: 33665 (131.50 KB)\n",
            "Non-trainable params: 0 (0.00 Byte)\n",
            "__________________________________________________________________________________________________\n",
            "Epoch 1/100\n",
            "638/638 [==============================] - ETA: 0s - loss: 0.4112 - accuracy: 0.8711 - precision_2: 0.8338 - recall_2: 0.9268\n",
            "Epoch 1: val_loss improved from inf to 0.33518, saving model to models/best_html_model2.keras\n",
            "638/638 [==============================] - 245s 382ms/step - loss: 0.4112 - accuracy: 0.8711 - precision_2: 0.8338 - recall_2: 0.9268 - val_loss: 0.3352 - val_accuracy: 0.8828 - val_precision_2: 0.8402 - val_recall_2: 0.9455\n",
            "Epoch 2/100\n",
            "638/638 [==============================] - ETA: 0s - loss: 0.3353 - accuracy: 0.8866 - precision_2: 0.8549 - recall_2: 0.9313\n",
            "Epoch 2: val_loss improved from 0.33518 to 0.31551, saving model to models/best_html_model2.keras\n",
            "638/638 [==============================] - 242s 379ms/step - loss: 0.3353 - accuracy: 0.8866 - precision_2: 0.8549 - recall_2: 0.9313 - val_loss: 0.3155 - val_accuracy: 0.8875 - val_precision_2: 0.8483 - val_recall_2: 0.9437\n",
            "Epoch 3/100\n",
            "638/638 [==============================] - ETA: 0s - loss: 0.3152 - accuracy: 0.8903 - precision_2: 0.8633 - recall_2: 0.9275\n",
            "Epoch 3: val_loss improved from 0.31551 to 0.30216, saving model to models/best_html_model2.keras\n",
            "638/638 [==============================] - 240s 377ms/step - loss: 0.3152 - accuracy: 0.8903 - precision_2: 0.8633 - recall_2: 0.9275 - val_loss: 0.3022 - val_accuracy: 0.8911 - val_precision_2: 0.8543 - val_recall_2: 0.9429\n",
            "Epoch 4/100\n",
            "638/638 [==============================] - ETA: 0s - loss: 0.3007 - accuracy: 0.8928 - precision_2: 0.8700 - recall_2: 0.9237\n",
            "Epoch 4: val_loss improved from 0.30216 to 0.28883, saving model to models/best_html_model2.keras\n",
            "638/638 [==============================] - 238s 373ms/step - loss: 0.3007 - accuracy: 0.8928 - precision_2: 0.8700 - recall_2: 0.9237 - val_loss: 0.2888 - val_accuracy: 0.8939 - val_precision_2: 0.8613 - val_recall_2: 0.9390\n",
            "Epoch 5/100\n",
            "638/638 [==============================] - ETA: 0s - loss: 0.2909 - accuracy: 0.8947 - precision_2: 0.8745 - recall_2: 0.9217\n",
            "Epoch 5: val_loss improved from 0.28883 to 0.27969, saving model to models/best_html_model2.keras\n",
            "638/638 [==============================] - 238s 374ms/step - loss: 0.2909 - accuracy: 0.8947 - precision_2: 0.8745 - recall_2: 0.9217 - val_loss: 0.2797 - val_accuracy: 0.8963 - val_precision_2: 0.8651 - val_recall_2: 0.9390\n",
            "Epoch 6/100\n",
            "638/638 [==============================] - ETA: 0s - loss: 0.2823 - accuracy: 0.8959 - precision_2: 0.8783 - recall_2: 0.9192\n",
            "Epoch 6: val_loss improved from 0.27969 to 0.27300, saving model to models/best_html_model2.keras\n",
            "638/638 [==============================] - 236s 369ms/step - loss: 0.2823 - accuracy: 0.8959 - precision_2: 0.8783 - recall_2: 0.9192 - val_loss: 0.2730 - val_accuracy: 0.8978 - val_precision_2: 0.8690 - val_recall_2: 0.9369\n",
            "Epoch 7/100\n",
            "638/638 [==============================] - ETA: 0s - loss: 0.2764 - accuracy: 0.8975 - precision_2: 0.8824 - recall_2: 0.9172\n",
            "Epoch 7: val_loss did not improve from 0.27300\n",
            "638/638 [==============================] - 235s 368ms/step - loss: 0.2764 - accuracy: 0.8975 - precision_2: 0.8824 - recall_2: 0.9172 - val_loss: 0.2768 - val_accuracy: 0.8952 - val_precision_2: 0.8626 - val_recall_2: 0.9402\n",
            "Epoch 8/100\n",
            "638/638 [==============================] - ETA: 0s - loss: 0.2732 - accuracy: 0.8972 - precision_2: 0.8833 - recall_2: 0.9153\n",
            "Epoch 8: val_loss did not improve from 0.27300\n",
            "638/638 [==============================] - 237s 371ms/step - loss: 0.2732 - accuracy: 0.8972 - precision_2: 0.8833 - recall_2: 0.9153 - val_loss: 0.2746 - val_accuracy: 0.8961 - val_precision_2: 0.8645 - val_recall_2: 0.9394\n",
            "Epoch 9/100\n",
            "638/638 [==============================] - ETA: 0s - loss: 0.2710 - accuracy: 0.8980 - precision_2: 0.8838 - recall_2: 0.9164\n",
            "Epoch 9: val_loss improved from 0.27300 to 0.26859, saving model to models/best_html_model2.keras\n",
            "638/638 [==============================] - 237s 371ms/step - loss: 0.2710 - accuracy: 0.8980 - precision_2: 0.8838 - recall_2: 0.9164 - val_loss: 0.2686 - val_accuracy: 0.8985 - val_precision_2: 0.8704 - val_recall_2: 0.9365\n",
            "Epoch 10/100\n",
            "638/638 [==============================] - ETA: 0s - loss: 0.2651 - accuracy: 0.8993 - precision_2: 0.8883 - recall_2: 0.9135\n",
            "Epoch 10: val_loss did not improve from 0.26859\n",
            "638/638 [==============================] - 235s 368ms/step - loss: 0.2651 - accuracy: 0.8993 - precision_2: 0.8883 - recall_2: 0.9135 - val_loss: 0.2698 - val_accuracy: 0.8993 - val_precision_2: 0.8713 - val_recall_2: 0.9371\n",
            "Epoch 11/100\n",
            "638/638 [==============================] - ETA: 0s - loss: 0.2646 - accuracy: 0.8989 - precision_2: 0.8884 - recall_2: 0.9125\n",
            "Epoch 11: val_loss improved from 0.26859 to 0.26294, saving model to models/best_html_model2.keras\n",
            "638/638 [==============================] - 236s 369ms/step - loss: 0.2646 - accuracy: 0.8989 - precision_2: 0.8884 - recall_2: 0.9125 - val_loss: 0.2629 - val_accuracy: 0.9024 - val_precision_2: 0.8764 - val_recall_2: 0.9369\n",
            "Epoch 12/100\n",
            "638/638 [==============================] - ETA: 0s - loss: 0.2611 - accuracy: 0.8992 - precision_2: 0.8896 - recall_2: 0.9116\n",
            "Epoch 12: val_loss did not improve from 0.26294\n",
            "638/638 [==============================] - 235s 368ms/step - loss: 0.2611 - accuracy: 0.8992 - precision_2: 0.8896 - recall_2: 0.9116 - val_loss: 0.2663 - val_accuracy: 0.8985 - val_precision_2: 0.8696 - val_recall_2: 0.9376\n",
            "Epoch 13/100\n",
            "638/638 [==============================] - ETA: 0s - loss: 0.2581 - accuracy: 0.9006 - precision_2: 0.8921 - recall_2: 0.9115\n",
            "Epoch 13: val_loss did not improve from 0.26294\n",
            "638/638 [==============================] - 236s 370ms/step - loss: 0.2581 - accuracy: 0.9006 - precision_2: 0.8921 - recall_2: 0.9115 - val_loss: 0.2666 - val_accuracy: 0.9006 - val_precision_2: 0.8732 - val_recall_2: 0.9373\n",
            "Epoch 14/100\n",
            "638/638 [==============================] - ETA: 0s - loss: 0.2580 - accuracy: 0.8996 - precision_2: 0.8921 - recall_2: 0.9091\n",
            "Epoch 14: val_loss improved from 0.26294 to 0.25701, saving model to models/best_html_model2.keras\n",
            "638/638 [==============================] - 236s 370ms/step - loss: 0.2580 - accuracy: 0.8996 - precision_2: 0.8921 - recall_2: 0.9091 - val_loss: 0.2570 - val_accuracy: 0.9040 - val_precision_2: 0.8822 - val_recall_2: 0.9325\n",
            "Epoch 15/100\n",
            "638/638 [==============================] - ETA: 0s - loss: 0.2566 - accuracy: 0.9001 - precision_2: 0.8923 - recall_2: 0.9102\n",
            "Epoch 15: val_loss did not improve from 0.25701\n",
            "638/638 [==============================] - 237s 371ms/step - loss: 0.2566 - accuracy: 0.9001 - precision_2: 0.8923 - recall_2: 0.9102 - val_loss: 0.2574 - val_accuracy: 0.9051 - val_precision_2: 0.8833 - val_recall_2: 0.9335\n",
            "Epoch 16/100\n",
            "638/638 [==============================] - ETA: 0s - loss: 0.2542 - accuracy: 0.9013 - precision_2: 0.8940 - recall_2: 0.9106\n",
            "Epoch 16: val_loss did not improve from 0.25701\n",
            "638/638 [==============================] - 236s 370ms/step - loss: 0.2542 - accuracy: 0.9013 - precision_2: 0.8940 - recall_2: 0.9106 - val_loss: 0.2670 - val_accuracy: 0.9076 - val_precision_2: 0.8761 - val_recall_2: 0.9496\n",
            "Epoch 17/100\n",
            "638/638 [==============================] - ETA: 0s - loss: 0.2515 - accuracy: 0.9019 - precision_2: 0.8950 - recall_2: 0.9106\n",
            "Epoch 17: val_loss improved from 0.25701 to 0.25442, saving model to models/best_html_model2.keras\n",
            "638/638 [==============================] - 236s 370ms/step - loss: 0.2515 - accuracy: 0.9019 - precision_2: 0.8950 - recall_2: 0.9106 - val_loss: 0.2544 - val_accuracy: 0.9029 - val_precision_2: 0.8776 - val_recall_2: 0.9365\n",
            "Epoch 18/100\n",
            "638/638 [==============================] - ETA: 0s - loss: 0.2515 - accuracy: 0.9024 - precision_2: 0.8946 - recall_2: 0.9122\n",
            "Epoch 18: val_loss improved from 0.25442 to 0.24730, saving model to models/best_html_model2.keras\n",
            "638/638 [==============================] - 237s 371ms/step - loss: 0.2515 - accuracy: 0.9024 - precision_2: 0.8946 - recall_2: 0.9122 - val_loss: 0.2473 - val_accuracy: 0.9083 - val_precision_2: 0.8775 - val_recall_2: 0.9492\n",
            "Epoch 19/100\n",
            "638/638 [==============================] - ETA: 0s - loss: 0.2500 - accuracy: 0.9042 - precision_2: 0.8964 - recall_2: 0.9140\n",
            "Epoch 19: val_loss did not improve from 0.24730\n",
            "638/638 [==============================] - 237s 372ms/step - loss: 0.2500 - accuracy: 0.9042 - precision_2: 0.8964 - recall_2: 0.9140 - val_loss: 0.2500 - val_accuracy: 0.9094 - val_precision_2: 0.8806 - val_recall_2: 0.9473\n",
            "Epoch 20/100\n",
            "638/638 [==============================] - ETA: 0s - loss: 0.2500 - accuracy: 0.9036 - precision_2: 0.8946 - recall_2: 0.9150\n",
            "Epoch 20: val_loss did not improve from 0.24730\n",
            "638/638 [==============================] - 238s 372ms/step - loss: 0.2500 - accuracy: 0.9036 - precision_2: 0.8946 - recall_2: 0.9150 - val_loss: 0.2509 - val_accuracy: 0.9125 - val_precision_2: 0.8824 - val_recall_2: 0.9520\n",
            "Epoch 21/100\n",
            "638/638 [==============================] - ETA: 0s - loss: 0.2469 - accuracy: 0.9055 - precision_2: 0.8966 - recall_2: 0.9166\n",
            "Epoch 21: val_loss improved from 0.24730 to 0.24393, saving model to models/best_html_model2.keras\n",
            "638/638 [==============================] - 236s 370ms/step - loss: 0.2469 - accuracy: 0.9055 - precision_2: 0.8966 - recall_2: 0.9166 - val_loss: 0.2439 - val_accuracy: 0.9073 - val_precision_2: 0.8746 - val_recall_2: 0.9508\n",
            "Epoch 22/100\n",
            "638/638 [==============================] - ETA: 0s - loss: 0.2481 - accuracy: 0.9062 - precision_2: 0.8967 - recall_2: 0.9181\n",
            "Epoch 22: val_loss did not improve from 0.24393\n",
            "638/638 [==============================] - 236s 369ms/step - loss: 0.2481 - accuracy: 0.9062 - precision_2: 0.8967 - recall_2: 0.9181 - val_loss: 0.2560 - val_accuracy: 0.9088 - val_precision_2: 0.8722 - val_recall_2: 0.9580\n",
            "Epoch 23/100\n",
            "638/638 [==============================] - ETA: 0s - loss: 0.2458 - accuracy: 0.9069 - precision_2: 0.8979 - recall_2: 0.9183\n",
            "Epoch 23: val_loss improved from 0.24393 to 0.23931, saving model to models/best_html_model2.keras\n",
            "638/638 [==============================] - 237s 371ms/step - loss: 0.2458 - accuracy: 0.9069 - precision_2: 0.8979 - recall_2: 0.9183 - val_loss: 0.2393 - val_accuracy: 0.9168 - val_precision_2: 0.8898 - val_recall_2: 0.9514\n",
            "Epoch 24/100\n",
            "638/638 [==============================] - ETA: 0s - loss: 0.2440 - accuracy: 0.9077 - precision_2: 0.8980 - recall_2: 0.9200\n",
            "Epoch 24: val_loss improved from 0.23931 to 0.23836, saving model to models/best_html_model2.keras\n",
            "638/638 [==============================] - 237s 372ms/step - loss: 0.2440 - accuracy: 0.9077 - precision_2: 0.8980 - recall_2: 0.9200 - val_loss: 0.2384 - val_accuracy: 0.9147 - val_precision_2: 0.8868 - val_recall_2: 0.9508\n",
            "Epoch 25/100\n",
            "638/638 [==============================] - ETA: 0s - loss: 0.2452 - accuracy: 0.9073 - precision_2: 0.8980 - recall_2: 0.9190\n",
            "Epoch 25: val_loss improved from 0.23836 to 0.23463, saving model to models/best_html_model2.keras\n",
            "638/638 [==============================] - 237s 371ms/step - loss: 0.2452 - accuracy: 0.9073 - precision_2: 0.8980 - recall_2: 0.9190 - val_loss: 0.2346 - val_accuracy: 0.9170 - val_precision_2: 0.8903 - val_recall_2: 0.9512\n",
            "Epoch 26/100\n",
            "638/638 [==============================] - ETA: 0s - loss: 0.2436 - accuracy: 0.9078 - precision_2: 0.8996 - recall_2: 0.9181\n",
            "Epoch 26: val_loss improved from 0.23463 to 0.22805, saving model to models/best_html_model2.keras\n",
            "638/638 [==============================] - 237s 371ms/step - loss: 0.2436 - accuracy: 0.9078 - precision_2: 0.8996 - recall_2: 0.9181 - val_loss: 0.2280 - val_accuracy: 0.9186 - val_precision_2: 0.8942 - val_recall_2: 0.9496\n",
            "Epoch 27/100\n",
            "638/638 [==============================] - ETA: 0s - loss: 0.2409 - accuracy: 0.9084 - precision_2: 0.9003 - recall_2: 0.9185\n",
            "Epoch 27: val_loss did not improve from 0.22805\n",
            "638/638 [==============================] - 236s 370ms/step - loss: 0.2409 - accuracy: 0.9084 - precision_2: 0.9003 - recall_2: 0.9185 - val_loss: 0.2327 - val_accuracy: 0.9160 - val_precision_2: 0.8864 - val_recall_2: 0.9543\n",
            "Epoch 28/100\n",
            "638/638 [==============================] - ETA: 0s - loss: 0.2424 - accuracy: 0.9085 - precision_2: 0.8990 - recall_2: 0.9204\n",
            "Epoch 28: val_loss did not improve from 0.22805\n",
            "638/638 [==============================] - 236s 370ms/step - loss: 0.2424 - accuracy: 0.9085 - precision_2: 0.8990 - recall_2: 0.9204 - val_loss: 0.2326 - val_accuracy: 0.9153 - val_precision_2: 0.8876 - val_recall_2: 0.9510\n",
            "Epoch 29/100\n",
            "638/638 [==============================] - ETA: 0s - loss: 0.2423 - accuracy: 0.9081 - precision_2: 0.8999 - recall_2: 0.9185\n",
            "Epoch 29: val_loss did not improve from 0.22805\n",
            "638/638 [==============================] - 236s 370ms/step - loss: 0.2423 - accuracy: 0.9081 - precision_2: 0.8999 - recall_2: 0.9185 - val_loss: 0.2311 - val_accuracy: 0.9166 - val_precision_2: 0.8899 - val_recall_2: 0.9508\n",
            "Epoch 30/100\n",
            "638/638 [==============================] - ETA: 0s - loss: 0.2385 - accuracy: 0.9094 - precision_2: 0.9015 - recall_2: 0.9193\n",
            "Epoch 30: val_loss improved from 0.22805 to 0.22709, saving model to models/best_html_model2.keras\n",
            "638/638 [==============================] - 237s 372ms/step - loss: 0.2385 - accuracy: 0.9094 - precision_2: 0.9015 - recall_2: 0.9193 - val_loss: 0.2271 - val_accuracy: 0.9186 - val_precision_2: 0.8941 - val_recall_2: 0.9498\n",
            "Epoch 31/100\n",
            "638/638 [==============================] - ETA: 0s - loss: 0.2383 - accuracy: 0.9106 - precision_2: 0.9027 - recall_2: 0.9204\n",
            "Epoch 31: val_loss improved from 0.22709 to 0.22450, saving model to models/best_html_model2.keras\n",
            "638/638 [==============================] - 235s 369ms/step - loss: 0.2383 - accuracy: 0.9106 - precision_2: 0.9027 - recall_2: 0.9204 - val_loss: 0.2245 - val_accuracy: 0.9199 - val_precision_2: 0.8955 - val_recall_2: 0.9508\n",
            "Epoch 32/100\n",
            "638/638 [==============================] - ETA: 0s - loss: 0.2387 - accuracy: 0.9111 - precision_2: 0.9020 - recall_2: 0.9225\n",
            "Epoch 32: val_loss did not improve from 0.22450\n",
            "638/638 [==============================] - 235s 368ms/step - loss: 0.2387 - accuracy: 0.9111 - precision_2: 0.9020 - recall_2: 0.9225 - val_loss: 0.2286 - val_accuracy: 0.9177 - val_precision_2: 0.8907 - val_recall_2: 0.9524\n",
            "Epoch 33/100\n",
            "638/638 [==============================] - ETA: 0s - loss: 0.2378 - accuracy: 0.9110 - precision_2: 0.9026 - recall_2: 0.9214\n",
            "Epoch 33: val_loss did not improve from 0.22450\n",
            "638/638 [==============================] - 235s 368ms/step - loss: 0.2378 - accuracy: 0.9110 - precision_2: 0.9026 - recall_2: 0.9214 - val_loss: 0.2329 - val_accuracy: 0.9151 - val_precision_2: 0.8837 - val_recall_2: 0.9561\n",
            "Epoch 34/100\n",
            "638/638 [==============================] - ETA: 0s - loss: 0.2365 - accuracy: 0.9117 - precision_2: 0.9037 - recall_2: 0.9216\n",
            "Epoch 34: val_loss did not improve from 0.22450\n",
            "638/638 [==============================] - 235s 368ms/step - loss: 0.2365 - accuracy: 0.9117 - precision_2: 0.9037 - recall_2: 0.9216 - val_loss: 0.2313 - val_accuracy: 0.9176 - val_precision_2: 0.8878 - val_recall_2: 0.9561\n",
            "Epoch 35/100\n",
            "638/638 [==============================] - ETA: 0s - loss: 0.2373 - accuracy: 0.9115 - precision_2: 0.9029 - recall_2: 0.9221\n",
            "Epoch 35: val_loss improved from 0.22450 to 0.22231, saving model to models/best_html_model2.keras\n",
            "638/638 [==============================] - 235s 368ms/step - loss: 0.2373 - accuracy: 0.9115 - precision_2: 0.9029 - recall_2: 0.9221 - val_loss: 0.2223 - val_accuracy: 0.9225 - val_precision_2: 0.9005 - val_recall_2: 0.9498\n",
            "Epoch 36/100\n",
            "638/638 [==============================] - ETA: 0s - loss: 0.2354 - accuracy: 0.9120 - precision_2: 0.9032 - recall_2: 0.9229\n",
            "Epoch 36: val_loss did not improve from 0.22231\n",
            "638/638 [==============================] - 234s 367ms/step - loss: 0.2354 - accuracy: 0.9120 - precision_2: 0.9032 - recall_2: 0.9229 - val_loss: 0.2249 - val_accuracy: 0.9204 - val_precision_2: 0.8950 - val_recall_2: 0.9525\n",
            "Epoch 37/100\n",
            "638/638 [==============================] - ETA: 0s - loss: 0.2350 - accuracy: 0.9121 - precision_2: 0.9033 - recall_2: 0.9230\n",
            "Epoch 37: val_loss improved from 0.22231 to 0.22110, saving model to models/best_html_model2.keras\n",
            "638/638 [==============================] - 235s 368ms/step - loss: 0.2350 - accuracy: 0.9121 - precision_2: 0.9033 - recall_2: 0.9230 - val_loss: 0.2211 - val_accuracy: 0.9199 - val_precision_2: 0.8949 - val_recall_2: 0.9516\n",
            "Epoch 38/100\n",
            "638/638 [==============================] - ETA: 0s - loss: 0.2380 - accuracy: 0.9112 - precision_2: 0.9016 - recall_2: 0.9233\n",
            "Epoch 38: val_loss improved from 0.22110 to 0.21807, saving model to models/best_html_model2.keras\n",
            "638/638 [==============================] - 235s 368ms/step - loss: 0.2380 - accuracy: 0.9112 - precision_2: 0.9016 - recall_2: 0.9233 - val_loss: 0.2181 - val_accuracy: 0.9197 - val_precision_2: 0.8973 - val_recall_2: 0.9478\n",
            "Epoch 39/100\n",
            "638/638 [==============================] - ETA: 0s - loss: 0.2349 - accuracy: 0.9129 - precision_2: 0.9032 - recall_2: 0.9248\n",
            "Epoch 39: val_loss did not improve from 0.21807\n",
            "638/638 [==============================] - 236s 370ms/step - loss: 0.2349 - accuracy: 0.9129 - precision_2: 0.9032 - recall_2: 0.9248 - val_loss: 0.2260 - val_accuracy: 0.9196 - val_precision_2: 0.8928 - val_recall_2: 0.9537\n",
            "Epoch 40/100\n",
            "638/638 [==============================] - ETA: 0s - loss: 0.2332 - accuracy: 0.9121 - precision_2: 0.9042 - recall_2: 0.9219\n",
            "Epoch 40: val_loss did not improve from 0.21807\n",
            "638/638 [==============================] - 238s 372ms/step - loss: 0.2332 - accuracy: 0.9121 - precision_2: 0.9042 - recall_2: 0.9219 - val_loss: 0.2196 - val_accuracy: 0.9219 - val_precision_2: 0.8995 - val_recall_2: 0.9498\n",
            "Epoch 41/100\n",
            "638/638 [==============================] - ETA: 0s - loss: 0.2359 - accuracy: 0.9119 - precision_2: 0.9024 - recall_2: 0.9237\n",
            "Epoch 41: val_loss improved from 0.21807 to 0.21550, saving model to models/best_html_model2.keras\n",
            "638/638 [==============================] - 236s 370ms/step - loss: 0.2359 - accuracy: 0.9119 - precision_2: 0.9024 - recall_2: 0.9237 - val_loss: 0.2155 - val_accuracy: 0.9235 - val_precision_2: 0.9019 - val_recall_2: 0.9504\n",
            "Epoch 42/100\n",
            "638/638 [==============================] - ETA: 0s - loss: 0.2341 - accuracy: 0.9127 - precision_2: 0.9048 - recall_2: 0.9225\n",
            "Epoch 42: val_loss did not improve from 0.21550\n",
            "638/638 [==============================] - 237s 372ms/step - loss: 0.2341 - accuracy: 0.9127 - precision_2: 0.9048 - recall_2: 0.9225 - val_loss: 0.2157 - val_accuracy: 0.9194 - val_precision_2: 0.8960 - val_recall_2: 0.9490\n",
            "Epoch 43/100\n",
            "638/638 [==============================] - ETA: 0s - loss: 0.2331 - accuracy: 0.9128 - precision_2: 0.9044 - recall_2: 0.9233\n",
            "Epoch 43: val_loss did not improve from 0.21550\n",
            "638/638 [==============================] - 236s 370ms/step - loss: 0.2331 - accuracy: 0.9128 - precision_2: 0.9044 - recall_2: 0.9233 - val_loss: 0.2254 - val_accuracy: 0.9169 - val_precision_2: 0.8864 - val_recall_2: 0.9563\n",
            "Epoch 44/100\n",
            "638/638 [==============================] - ETA: 0s - loss: 0.2325 - accuracy: 0.9137 - precision_2: 0.9053 - recall_2: 0.9241\n",
            "Epoch 44: val_loss did not improve from 0.21550\n",
            "638/638 [==============================] - 234s 367ms/step - loss: 0.2325 - accuracy: 0.9137 - precision_2: 0.9053 - recall_2: 0.9241 - val_loss: 0.2157 - val_accuracy: 0.9216 - val_precision_2: 0.8980 - val_recall_2: 0.9512\n",
            "Epoch 45/100\n",
            "638/638 [==============================] - ETA: 0s - loss: 0.2325 - accuracy: 0.9133 - precision_2: 0.9041 - recall_2: 0.9247\n",
            "Epoch 45: val_loss improved from 0.21550 to 0.21544, saving model to models/best_html_model2.keras\n",
            "638/638 [==============================] - 236s 370ms/step - loss: 0.2325 - accuracy: 0.9133 - precision_2: 0.9041 - recall_2: 0.9247 - val_loss: 0.2154 - val_accuracy: 0.9221 - val_precision_2: 0.9009 - val_recall_2: 0.9484\n",
            "Epoch 46/100\n",
            "638/638 [==============================] - ETA: 0s - loss: 0.2329 - accuracy: 0.9130 - precision_2: 0.9047 - recall_2: 0.9234\n",
            "Epoch 46: val_loss did not improve from 0.21544\n",
            "638/638 [==============================] - 237s 372ms/step - loss: 0.2329 - accuracy: 0.9130 - precision_2: 0.9047 - recall_2: 0.9234 - val_loss: 0.2157 - val_accuracy: 0.9209 - val_precision_2: 0.8995 - val_recall_2: 0.9476\n",
            "Epoch 47/100\n",
            "638/638 [==============================] - ETA: 0s - loss: 0.2329 - accuracy: 0.9127 - precision_2: 0.9029 - recall_2: 0.9250\n",
            "Epoch 47: val_loss did not improve from 0.21544\n",
            "638/638 [==============================] - 236s 370ms/step - loss: 0.2329 - accuracy: 0.9127 - precision_2: 0.9029 - recall_2: 0.9250 - val_loss: 0.2380 - val_accuracy: 0.9086 - val_precision_2: 0.8702 - val_recall_2: 0.9606\n",
            "Epoch 48/100\n",
            "638/638 [==============================] - ETA: 0s - loss: 0.2323 - accuracy: 0.9144 - precision_2: 0.9059 - recall_2: 0.9249\n",
            "Epoch 48: val_loss did not improve from 0.21544\n",
            "638/638 [==============================] - 235s 368ms/step - loss: 0.2323 - accuracy: 0.9144 - precision_2: 0.9059 - recall_2: 0.9249 - val_loss: 0.2211 - val_accuracy: 0.9175 - val_precision_2: 0.8878 - val_recall_2: 0.9559\n",
            "Epoch 49/100\n",
            "638/638 [==============================] - ETA: 0s - loss: 0.2297 - accuracy: 0.9142 - precision_2: 0.9044 - recall_2: 0.9263\n",
            "Epoch 49: val_loss improved from 0.21544 to 0.21332, saving model to models/best_html_model2.keras\n",
            "638/638 [==============================] - 235s 368ms/step - loss: 0.2297 - accuracy: 0.9142 - precision_2: 0.9044 - recall_2: 0.9263 - val_loss: 0.2133 - val_accuracy: 0.9237 - val_precision_2: 0.9012 - val_recall_2: 0.9518\n",
            "Epoch 50/100\n",
            "638/638 [==============================] - ETA: 0s - loss: 0.2307 - accuracy: 0.9146 - precision_2: 0.9057 - recall_2: 0.9256\n",
            "Epoch 50: val_loss did not improve from 0.21332\n",
            "638/638 [==============================] - 236s 369ms/step - loss: 0.2307 - accuracy: 0.9146 - precision_2: 0.9057 - recall_2: 0.9256 - val_loss: 0.2145 - val_accuracy: 0.9231 - val_precision_2: 0.8970 - val_recall_2: 0.9561\n",
            "Epoch 51/100\n",
            "638/638 [==============================] - ETA: 0s - loss: 0.2314 - accuracy: 0.9144 - precision_2: 0.9049 - recall_2: 0.9262\n",
            "Epoch 51: val_loss did not improve from 0.21332\n",
            "638/638 [==============================] - 234s 367ms/step - loss: 0.2314 - accuracy: 0.9144 - precision_2: 0.9049 - recall_2: 0.9262 - val_loss: 0.2152 - val_accuracy: 0.9222 - val_precision_2: 0.8975 - val_recall_2: 0.9531\n",
            "Epoch 52/100\n",
            "638/638 [==============================] - ETA: 0s - loss: 0.2318 - accuracy: 0.9142 - precision_2: 0.9048 - recall_2: 0.9257\n",
            "Epoch 52: val_loss did not improve from 0.21332\n",
            "638/638 [==============================] - 236s 370ms/step - loss: 0.2318 - accuracy: 0.9142 - precision_2: 0.9048 - recall_2: 0.9257 - val_loss: 0.2221 - val_accuracy: 0.9177 - val_precision_2: 0.8886 - val_recall_2: 0.9553\n",
            "Epoch 53/100\n",
            "638/638 [==============================] - ETA: 0s - loss: 0.2286 - accuracy: 0.9155 - precision_2: 0.9059 - recall_2: 0.9274\n",
            "Epoch 53: val_loss did not improve from 0.21332\n",
            "638/638 [==============================] - 235s 369ms/step - loss: 0.2286 - accuracy: 0.9155 - precision_2: 0.9059 - recall_2: 0.9274 - val_loss: 0.2158 - val_accuracy: 0.9215 - val_precision_2: 0.8955 - val_recall_2: 0.9543\n",
            "Epoch 54/100\n",
            "638/638 [==============================] - ETA: 0s - loss: 0.2290 - accuracy: 0.9151 - precision_2: 0.9058 - recall_2: 0.9266\n",
            "Epoch 54: val_loss improved from 0.21332 to 0.21157, saving model to models/best_html_model2.keras\n",
            "638/638 [==============================] - 235s 368ms/step - loss: 0.2290 - accuracy: 0.9151 - precision_2: 0.9058 - recall_2: 0.9266 - val_loss: 0.2116 - val_accuracy: 0.9241 - val_precision_2: 0.9041 - val_recall_2: 0.9488\n",
            "Epoch 55/100\n",
            "638/638 [==============================] - ETA: 0s - loss: 0.2285 - accuracy: 0.9154 - precision_2: 0.9067 - recall_2: 0.9261\n",
            "Epoch 55: val_loss improved from 0.21157 to 0.21080, saving model to models/best_html_model2.keras\n",
            "638/638 [==============================] - 237s 371ms/step - loss: 0.2285 - accuracy: 0.9154 - precision_2: 0.9067 - recall_2: 0.9261 - val_loss: 0.2108 - val_accuracy: 0.9233 - val_precision_2: 0.8998 - val_recall_2: 0.9527\n",
            "Epoch 56/100\n",
            "638/638 [==============================] - ETA: 0s - loss: 0.2297 - accuracy: 0.9151 - precision_2: 0.9060 - recall_2: 0.9262\n",
            "Epoch 56: val_loss did not improve from 0.21080\n",
            "638/638 [==============================] - 235s 368ms/step - loss: 0.2297 - accuracy: 0.9151 - precision_2: 0.9060 - recall_2: 0.9262 - val_loss: 0.2120 - val_accuracy: 0.9252 - val_precision_2: 0.9046 - val_recall_2: 0.9506\n",
            "Epoch 57/100\n",
            "638/638 [==============================] - ETA: 0s - loss: 0.2284 - accuracy: 0.9147 - precision_2: 0.9060 - recall_2: 0.9255\n",
            "Epoch 57: val_loss did not improve from 0.21080\n",
            "638/638 [==============================] - 234s 367ms/step - loss: 0.2284 - accuracy: 0.9147 - precision_2: 0.9060 - recall_2: 0.9255 - val_loss: 0.2150 - val_accuracy: 0.9232 - val_precision_2: 0.9011 - val_recall_2: 0.9508\n",
            "Epoch 58/100\n",
            "638/638 [==============================] - ETA: 0s - loss: 0.2287 - accuracy: 0.9152 - precision_2: 0.9063 - recall_2: 0.9262\n",
            "Epoch 58: val_loss did not improve from 0.21080\n",
            "638/638 [==============================] - 233s 365ms/step - loss: 0.2287 - accuracy: 0.9152 - precision_2: 0.9063 - recall_2: 0.9262 - val_loss: 0.2131 - val_accuracy: 0.9225 - val_precision_2: 0.9000 - val_recall_2: 0.9508\n",
            "Epoch 59/100\n",
            "638/638 [==============================] - ETA: 0s - loss: 0.2278 - accuracy: 0.9164 - precision_2: 0.9072 - recall_2: 0.9276\n",
            "Epoch 59: val_loss improved from 0.21080 to 0.21051, saving model to models/best_html_model2.keras\n",
            "638/638 [==============================] - 233s 366ms/step - loss: 0.2278 - accuracy: 0.9164 - precision_2: 0.9072 - recall_2: 0.9276 - val_loss: 0.2105 - val_accuracy: 0.9228 - val_precision_2: 0.8991 - val_recall_2: 0.9525\n",
            "Epoch 60/100\n",
            "638/638 [==============================] - ETA: 0s - loss: 0.2287 - accuracy: 0.9157 - precision_2: 0.9075 - recall_2: 0.9259\n",
            "Epoch 60: val_loss did not improve from 0.21051\n",
            "638/638 [==============================] - 233s 365ms/step - loss: 0.2287 - accuracy: 0.9157 - precision_2: 0.9075 - recall_2: 0.9259 - val_loss: 0.2110 - val_accuracy: 0.9239 - val_precision_2: 0.9004 - val_recall_2: 0.9533\n",
            "Epoch 61/100\n",
            "638/638 [==============================] - ETA: 0s - loss: 0.2275 - accuracy: 0.9171 - precision_2: 0.9085 - recall_2: 0.9277\n",
            "Epoch 61: val_loss did not improve from 0.21051\n",
            "638/638 [==============================] - 234s 368ms/step - loss: 0.2275 - accuracy: 0.9171 - precision_2: 0.9085 - recall_2: 0.9277 - val_loss: 0.2119 - val_accuracy: 0.9231 - val_precision_2: 0.9013 - val_recall_2: 0.9504\n",
            "Epoch 62/100\n",
            "638/638 [==============================] - ETA: 0s - loss: 0.2262 - accuracy: 0.9165 - precision_2: 0.9067 - recall_2: 0.9285\n",
            "Epoch 62: val_loss improved from 0.21051 to 0.20816, saving model to models/best_html_model2.keras\n",
            "638/638 [==============================] - 233s 365ms/step - loss: 0.2262 - accuracy: 0.9165 - precision_2: 0.9067 - recall_2: 0.9285 - val_loss: 0.2082 - val_accuracy: 0.9258 - val_precision_2: 0.9043 - val_recall_2: 0.9524\n",
            "Epoch 63/100\n",
            "638/638 [==============================] - ETA: 0s - loss: 0.2251 - accuracy: 0.9165 - precision_2: 0.9074 - recall_2: 0.9277\n",
            "Epoch 63: val_loss improved from 0.20816 to 0.20629, saving model to models/best_html_model2.keras\n",
            "638/638 [==============================] - 234s 367ms/step - loss: 0.2251 - accuracy: 0.9165 - precision_2: 0.9074 - recall_2: 0.9277 - val_loss: 0.2063 - val_accuracy: 0.9257 - val_precision_2: 0.9072 - val_recall_2: 0.9484\n",
            "Epoch 64/100\n",
            "638/638 [==============================] - ETA: 0s - loss: 0.2263 - accuracy: 0.9167 - precision_2: 0.9074 - recall_2: 0.9281\n",
            "Epoch 64: val_loss did not improve from 0.20629\n",
            "638/638 [==============================] - 232s 364ms/step - loss: 0.2263 - accuracy: 0.9167 - precision_2: 0.9074 - recall_2: 0.9281 - val_loss: 0.2066 - val_accuracy: 0.9259 - val_precision_2: 0.9046 - val_recall_2: 0.9522\n",
            "Epoch 65/100\n",
            "638/638 [==============================] - ETA: 0s - loss: 0.2260 - accuracy: 0.9154 - precision_2: 0.9063 - recall_2: 0.9266\n",
            "Epoch 65: val_loss did not improve from 0.20629\n",
            "638/638 [==============================] - 235s 368ms/step - loss: 0.2260 - accuracy: 0.9154 - precision_2: 0.9063 - recall_2: 0.9266 - val_loss: 0.2088 - val_accuracy: 0.9257 - val_precision_2: 0.9058 - val_recall_2: 0.9502\n",
            "Epoch 66/100\n",
            "638/638 [==============================] - ETA: 0s - loss: 0.2250 - accuracy: 0.9171 - precision_2: 0.9086 - recall_2: 0.9276\n",
            "Epoch 66: val_loss improved from 0.20629 to 0.20445, saving model to models/best_html_model2.keras\n",
            "638/638 [==============================] - 236s 370ms/step - loss: 0.2250 - accuracy: 0.9171 - precision_2: 0.9086 - recall_2: 0.9276 - val_loss: 0.2044 - val_accuracy: 0.9265 - val_precision_2: 0.9084 - val_recall_2: 0.9486\n",
            "Epoch 67/100\n",
            "638/638 [==============================] - ETA: 0s - loss: 0.2233 - accuracy: 0.9166 - precision_2: 0.9092 - recall_2: 0.9256\n",
            "Epoch 67: val_loss did not improve from 0.20445\n",
            "638/638 [==============================] - 236s 370ms/step - loss: 0.2233 - accuracy: 0.9166 - precision_2: 0.9092 - recall_2: 0.9256 - val_loss: 0.2107 - val_accuracy: 0.9228 - val_precision_2: 0.9006 - val_recall_2: 0.9506\n",
            "Epoch 68/100\n",
            "638/638 [==============================] - ETA: 0s - loss: 0.2244 - accuracy: 0.9165 - precision_2: 0.9088 - recall_2: 0.9259\n",
            "Epoch 68: val_loss did not improve from 0.20445\n",
            "638/638 [==============================] - 234s 367ms/step - loss: 0.2244 - accuracy: 0.9165 - precision_2: 0.9088 - recall_2: 0.9259 - val_loss: 0.2067 - val_accuracy: 0.9242 - val_precision_2: 0.9043 - val_recall_2: 0.9488\n",
            "Epoch 69/100\n",
            "638/638 [==============================] - ETA: 0s - loss: 0.2234 - accuracy: 0.9165 - precision_2: 0.9093 - recall_2: 0.9254\n",
            "Epoch 69: val_loss improved from 0.20445 to 0.20311, saving model to models/best_html_model2.keras\n",
            "638/638 [==============================] - 234s 367ms/step - loss: 0.2234 - accuracy: 0.9165 - precision_2: 0.9093 - recall_2: 0.9254 - val_loss: 0.2031 - val_accuracy: 0.9266 - val_precision_2: 0.9095 - val_recall_2: 0.9475\n",
            "Epoch 70/100\n",
            "638/638 [==============================] - ETA: 0s - loss: 0.2219 - accuracy: 0.9171 - precision_2: 0.9094 - recall_2: 0.9265\n",
            "Epoch 70: val_loss did not improve from 0.20311\n",
            "638/638 [==============================] - 233s 366ms/step - loss: 0.2219 - accuracy: 0.9171 - precision_2: 0.9094 - recall_2: 0.9265 - val_loss: 0.2044 - val_accuracy: 0.9276 - val_precision_2: 0.9103 - val_recall_2: 0.9488\n",
            "Epoch 71/100\n",
            "638/638 [==============================] - ETA: 0s - loss: 0.2263 - accuracy: 0.9158 - precision_2: 0.9087 - recall_2: 0.9245\n",
            "Epoch 71: val_loss did not improve from 0.20311\n",
            "638/638 [==============================] - 235s 368ms/step - loss: 0.2263 - accuracy: 0.9158 - precision_2: 0.9087 - recall_2: 0.9245 - val_loss: 0.2046 - val_accuracy: 0.9268 - val_precision_2: 0.9123 - val_recall_2: 0.9443\n",
            "Epoch 72/100\n",
            "638/638 [==============================] - ETA: 0s - loss: 0.2226 - accuracy: 0.9175 - precision_2: 0.9107 - recall_2: 0.9257\n",
            "Epoch 72: val_loss did not improve from 0.20311\n",
            "638/638 [==============================] - 234s 366ms/step - loss: 0.2226 - accuracy: 0.9175 - precision_2: 0.9107 - recall_2: 0.9257 - val_loss: 0.2047 - val_accuracy: 0.9268 - val_precision_2: 0.9087 - val_recall_2: 0.9488\n",
            "Epoch 73/100\n",
            "638/638 [==============================] - ETA: 0s - loss: 0.2215 - accuracy: 0.9171 - precision_2: 0.9102 - recall_2: 0.9255\n",
            "Epoch 73: val_loss improved from 0.20311 to 0.20085, saving model to models/best_html_model2.keras\n",
            "638/638 [==============================] - 234s 366ms/step - loss: 0.2215 - accuracy: 0.9171 - precision_2: 0.9102 - recall_2: 0.9255 - val_loss: 0.2009 - val_accuracy: 0.9274 - val_precision_2: 0.9118 - val_recall_2: 0.9463\n",
            "Epoch 74/100\n",
            "638/638 [==============================] - ETA: 0s - loss: 0.2225 - accuracy: 0.9174 - precision_2: 0.9107 - recall_2: 0.9255\n",
            "Epoch 74: val_loss did not improve from 0.20085\n",
            "638/638 [==============================] - 233s 366ms/step - loss: 0.2225 - accuracy: 0.9174 - precision_2: 0.9107 - recall_2: 0.9255 - val_loss: 0.2041 - val_accuracy: 0.9275 - val_precision_2: 0.9112 - val_recall_2: 0.9475\n",
            "Epoch 75/100\n",
            "638/638 [==============================] - ETA: 0s - loss: 0.2232 - accuracy: 0.9168 - precision_2: 0.9105 - recall_2: 0.9243\n",
            "Epoch 75: val_loss did not improve from 0.20085\n",
            "638/638 [==============================] - 232s 364ms/step - loss: 0.2232 - accuracy: 0.9168 - precision_2: 0.9105 - recall_2: 0.9243 - val_loss: 0.2036 - val_accuracy: 0.9275 - val_precision_2: 0.9112 - val_recall_2: 0.9473\n",
            "Epoch 76/100\n",
            "638/638 [==============================] - ETA: 0s - loss: 0.2209 - accuracy: 0.9178 - precision_2: 0.9114 - recall_2: 0.9255\n",
            "Epoch 76: val_loss did not improve from 0.20085\n",
            "638/638 [==============================] - 234s 366ms/step - loss: 0.2209 - accuracy: 0.9178 - precision_2: 0.9114 - recall_2: 0.9255 - val_loss: 0.2038 - val_accuracy: 0.9265 - val_precision_2: 0.9108 - val_recall_2: 0.9455\n",
            "Epoch 77/100\n",
            "638/638 [==============================] - ETA: 0s - loss: 0.2208 - accuracy: 0.9177 - precision_2: 0.9115 - recall_2: 0.9252\n",
            "Epoch 77: val_loss did not improve from 0.20085\n",
            "638/638 [==============================] - 235s 368ms/step - loss: 0.2208 - accuracy: 0.9177 - precision_2: 0.9115 - recall_2: 0.9252 - val_loss: 0.2083 - val_accuracy: 0.9259 - val_precision_2: 0.9054 - val_recall_2: 0.9512\n",
            "Epoch 78/100\n",
            "638/638 [==============================] - ETA: 0s - loss: 0.2208 - accuracy: 0.9173 - precision_2: 0.9104 - recall_2: 0.9257\n",
            "Epoch 78: val_loss did not improve from 0.20085\n",
            "Restoring model weights from the end of the best epoch: 73.\n",
            "638/638 [==============================] - 233s 365ms/step - loss: 0.2208 - accuracy: 0.9173 - precision_2: 0.9104 - recall_2: 0.9257 - val_loss: 0.2037 - val_accuracy: 0.9254 - val_precision_2: 0.9026 - val_recall_2: 0.9537\n",
            "Epoch 78: early stopping\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "best_html_model2 = keras.models.load_model(\n",
        "    'models/best_html_model2.keras',\n",
        "    custom_objects={'GCNConv': GCNConv,\n",
        "                    'GlobalSumPool': GlobalSumPool,\n",
        "                    'GCN': GCN})"
      ],
      "metadata": {
        "id": "YSLGENf8qSwX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "results = best_html_model2.evaluate(html_test_dataset, verbose=1)\n",
        "precision = results[2]\n",
        "recall = results[3]\n",
        "f1_score = 2 * (precision * recall) / (precision + recall)\n",
        "print(f\"F1-Score: {f1_score:.4f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eK2Y0kAUqUob",
        "outputId": "3c4a8f05-e693-4dac-f746-acfa7a80b162"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "80/80 [==============================] - 14s 168ms/step - loss: 0.2100 - accuracy: 0.9195 - precision_2: 0.9061 - recall_2: 0.9361\n",
            "F1-Score: 0.9208\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Experiment 3**"
      ],
      "metadata": {
        "id": "nuVdmtAmdhjr"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Train model"
      ],
      "metadata": {
        "id": "EXwjL7Sddls1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def create_html_model(max_nodes, feature_dim, gcn_units, dropout=0.1,\n",
        "                      num_gcn_layers=1, dense_dim=128, l2_reg=5e-4):\n",
        "    inputs_adj = keras.Input(shape=(max_nodes, max_nodes), dtype=tf.float32)\n",
        "    inputs_feat = keras.Input(shape=(max_nodes, feature_dim), dtype=tf.float32)\n",
        "\n",
        "    x = inputs_feat\n",
        "    for _ in range(num_gcn_layers):\n",
        "        x = GCN(gcn_units, activation='relu')([x, inputs_adj])\n",
        "        x = layers.Dropout(dropout)(x)\n",
        "    x = layers.Flatten()(x)\n",
        "    x = layers.Dense(dense_dim,\n",
        "                     activation='relu',\n",
        "                     kernel_regularizer=regularizers.l2(l2_reg))(x)\n",
        "    x = layers.Dropout(dropout)(x)\n",
        "    outputs = layers.Dense(1, activation='sigmoid')(x)\n",
        "    html_model = keras.Model(inputs=[inputs_adj, inputs_feat], outputs=outputs)\n",
        "\n",
        "    return html_model"
      ],
      "metadata": {
        "id": "bfes07RXdz8h"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = create_html_model(max_nodes=max_nodes,\n",
        "                          feature_dim=feature_dim,\n",
        "                          gcn_units=128,\n",
        "                          num_gcn_layers=2,\n",
        "                          dropout=0.3,\n",
        "                          dense_dim=128,\n",
        "                          l2_reg=5e-4)\n",
        "\n",
        "model.summary()\n",
        "\n",
        "optimizer = keras.optimizers.Adam(learning_rate=1e-3)\n",
        "metrics = ['accuracy', tf.keras.metrics.Precision(), tf.keras.metrics.Recall()]\n",
        "model.compile(optimizer=optimizer, loss='binary_crossentropy', metrics=metrics)\n",
        "\n",
        "checkpoint_filepath = 'models/best_html_model3.keras'\n",
        "\n",
        "checkpoint_callback = tf.keras.callbacks.ModelCheckpoint(\n",
        "    filepath=checkpoint_filepath,\n",
        "    save_weights_only=False,\n",
        "    monitor='val_loss',\n",
        "    mode='min',\n",
        "    save_best_only=True,\n",
        "    verbose=1\n",
        ")\n",
        "\n",
        "early_stopping = tf.keras.callbacks.EarlyStopping(\n",
        "    monitor='val_loss',\n",
        "    patience=5,\n",
        "    restore_best_weights=True,\n",
        "    verbose=1\n",
        ")\n",
        "\n",
        "history = model.fit(html_train_dataset,\n",
        "                    validation_data=html_val_dataset,\n",
        "                    epochs=100,\n",
        "                    callbacks=[checkpoint_callback, early_stopping])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "L1IansyQd9JF",
        "outputId": "d7a33822-c5df-4d27-d256-a13c70dff9e2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"model_3\"\n",
            "__________________________________________________________________________________________________\n",
            " Layer (type)                Output Shape                 Param #   Connected to                  \n",
            "==================================================================================================\n",
            " input_12 (InputLayer)       [(None, 600, 3)]             0         []                            \n",
            "                                                                                                  \n",
            " input_11 (InputLayer)       [(None, 600, 600)]           0         []                            \n",
            "                                                                                                  \n",
            " gcn_12 (GCN)                (None, 600, 128)             512       ['input_12[0][0]',            \n",
            "                                                                     'input_11[0][0]']            \n",
            "                                                                                                  \n",
            " dropout_13 (Dropout)        (None, 600, 128)             0         ['gcn_12[0][0]']              \n",
            "                                                                                                  \n",
            " gcn_13 (GCN)                (None, 600, 128)             16512     ['dropout_13[0][0]',          \n",
            "                                                                     'input_11[0][0]']            \n",
            "                                                                                                  \n",
            " dropout_14 (Dropout)        (None, 600, 128)             0         ['gcn_13[0][0]']              \n",
            "                                                                                                  \n",
            " flatten (Flatten)           (None, 76800)                0         ['dropout_14[0][0]']          \n",
            "                                                                                                  \n",
            " dense_7 (Dense)             (None, 128)                  9830528   ['flatten[0][0]']             \n",
            "                                                                                                  \n",
            " dropout_15 (Dropout)        (None, 128)                  0         ['dense_7[0][0]']             \n",
            "                                                                                                  \n",
            " dense_8 (Dense)             (None, 1)                    129       ['dropout_15[0][0]']          \n",
            "                                                                                                  \n",
            "==================================================================================================\n",
            "Total params: 9847681 (37.57 MB)\n",
            "Trainable params: 9847681 (37.57 MB)\n",
            "Non-trainable params: 0 (0.00 Byte)\n",
            "__________________________________________________________________________________________________\n",
            "Epoch 1/100\n",
            "638/638 [==============================] - ETA: 0s - loss: 0.3407 - accuracy: 0.9027 - precision_3: 0.8731 - recall_3: 0.9424\n",
            "Epoch 1: val_loss improved from inf to 0.30382, saving model to models/best_html_model3.keras\n",
            "638/638 [==============================] - 267s 416ms/step - loss: 0.3407 - accuracy: 0.9027 - precision_3: 0.8731 - recall_3: 0.9424 - val_loss: 0.3038 - val_accuracy: 0.9160 - val_precision_3: 0.8859 - val_recall_3: 0.9549\n",
            "Epoch 2/100\n",
            "638/638 [==============================] - ETA: 0s - loss: 0.3222 - accuracy: 0.9114 - precision_3: 0.8870 - recall_3: 0.9430\n",
            "Epoch 2: val_loss did not improve from 0.30382\n",
            "638/638 [==============================] - 260s 408ms/step - loss: 0.3222 - accuracy: 0.9114 - precision_3: 0.8870 - recall_3: 0.9430 - val_loss: 0.3202 - val_accuracy: 0.9109 - val_precision_3: 0.8706 - val_recall_3: 0.9653\n",
            "Epoch 3/100\n",
            "638/638 [==============================] - ETA: 0s - loss: 0.3135 - accuracy: 0.9144 - precision_3: 0.8922 - recall_3: 0.9427\n",
            "Epoch 3: val_loss improved from 0.30382 to 0.30356, saving model to models/best_html_model3.keras\n",
            "638/638 [==============================] - 259s 406ms/step - loss: 0.3135 - accuracy: 0.9144 - precision_3: 0.8922 - recall_3: 0.9427 - val_loss: 0.3036 - val_accuracy: 0.9146 - val_precision_3: 0.8752 - val_recall_3: 0.9671\n",
            "Epoch 4/100\n",
            "638/638 [==============================] - ETA: 0s - loss: 0.3064 - accuracy: 0.9163 - precision_3: 0.8953 - recall_3: 0.9429\n",
            "Epoch 4: val_loss improved from 0.30356 to 0.29738, saving model to models/best_html_model3.keras\n",
            "638/638 [==============================] - 258s 405ms/step - loss: 0.3064 - accuracy: 0.9163 - precision_3: 0.8953 - recall_3: 0.9429 - val_loss: 0.2974 - val_accuracy: 0.9167 - val_precision_3: 0.8832 - val_recall_3: 0.9604\n",
            "Epoch 5/100\n",
            "638/638 [==============================] - ETA: 0s - loss: 0.3010 - accuracy: 0.9177 - precision_3: 0.8972 - recall_3: 0.9435\n",
            "Epoch 5: val_loss improved from 0.29738 to 0.28737, saving model to models/best_html_model3.keras\n",
            "638/638 [==============================] - 259s 407ms/step - loss: 0.3010 - accuracy: 0.9177 - precision_3: 0.8972 - recall_3: 0.9435 - val_loss: 0.2874 - val_accuracy: 0.9192 - val_precision_3: 0.8858 - val_recall_3: 0.9625\n",
            "Epoch 6/100\n",
            "638/638 [==============================] - ETA: 0s - loss: 0.2982 - accuracy: 0.9181 - precision_3: 0.8973 - recall_3: 0.9441\n",
            "Epoch 6: val_loss did not improve from 0.28737\n",
            "638/638 [==============================] - 260s 408ms/step - loss: 0.2982 - accuracy: 0.9181 - precision_3: 0.8973 - recall_3: 0.9441 - val_loss: 0.2990 - val_accuracy: 0.9164 - val_precision_3: 0.8790 - val_recall_3: 0.9657\n",
            "Epoch 7/100\n",
            "638/638 [==============================] - ETA: 0s - loss: 0.2895 - accuracy: 0.9197 - precision_3: 0.9003 - recall_3: 0.9438\n",
            "Epoch 7: val_loss improved from 0.28737 to 0.28732, saving model to models/best_html_model3.keras\n",
            "638/638 [==============================] - 261s 409ms/step - loss: 0.2895 - accuracy: 0.9197 - precision_3: 0.9003 - recall_3: 0.9438 - val_loss: 0.2873 - val_accuracy: 0.9188 - val_precision_3: 0.8858 - val_recall_3: 0.9616\n",
            "Epoch 8/100\n",
            "638/638 [==============================] - ETA: 0s - loss: 0.2931 - accuracy: 0.9201 - precision_3: 0.9006 - recall_3: 0.9445\n",
            "Epoch 8: val_loss improved from 0.28732 to 0.27691, saving model to models/best_html_model3.keras\n",
            "638/638 [==============================] - 256s 402ms/step - loss: 0.2931 - accuracy: 0.9201 - precision_3: 0.9006 - recall_3: 0.9445 - val_loss: 0.2769 - val_accuracy: 0.9224 - val_precision_3: 0.8911 - val_recall_3: 0.9624\n",
            "Epoch 9/100\n",
            "638/638 [==============================] - ETA: 0s - loss: 0.2870 - accuracy: 0.9216 - precision_3: 0.9026 - recall_3: 0.9451\n",
            "Epoch 9: val_loss did not improve from 0.27691\n",
            "638/638 [==============================] - 261s 410ms/step - loss: 0.2870 - accuracy: 0.9216 - precision_3: 0.9026 - recall_3: 0.9451 - val_loss: 0.2775 - val_accuracy: 0.9259 - val_precision_3: 0.8975 - val_recall_3: 0.9616\n",
            "Epoch 10/100\n",
            "638/638 [==============================] - ETA: 0s - loss: 0.2801 - accuracy: 0.9223 - precision_3: 0.9046 - recall_3: 0.9441\n",
            "Epoch 10: val_loss did not improve from 0.27691\n",
            "638/638 [==============================] - 262s 410ms/step - loss: 0.2801 - accuracy: 0.9223 - precision_3: 0.9046 - recall_3: 0.9441 - val_loss: 0.2784 - val_accuracy: 0.9236 - val_precision_3: 0.8940 - val_recall_3: 0.9612\n",
            "Epoch 11/100\n",
            "638/638 [==============================] - ETA: 0s - loss: 0.2818 - accuracy: 0.9229 - precision_3: 0.9058 - recall_3: 0.9441\n",
            "Epoch 11: val_loss improved from 0.27691 to 0.27070, saving model to models/best_html_model3.keras\n",
            "638/638 [==============================] - 262s 411ms/step - loss: 0.2818 - accuracy: 0.9229 - precision_3: 0.9058 - recall_3: 0.9441 - val_loss: 0.2707 - val_accuracy: 0.9275 - val_precision_3: 0.9025 - val_recall_3: 0.9584\n",
            "Epoch 12/100\n",
            "638/638 [==============================] - ETA: 0s - loss: 0.2769 - accuracy: 0.9238 - precision_3: 0.9068 - recall_3: 0.9447\n",
            "Epoch 12: val_loss improved from 0.27070 to 0.26398, saving model to models/best_html_model3.keras\n",
            "638/638 [==============================] - 261s 409ms/step - loss: 0.2769 - accuracy: 0.9238 - precision_3: 0.9068 - recall_3: 0.9447 - val_loss: 0.2640 - val_accuracy: 0.9291 - val_precision_3: 0.9013 - val_recall_3: 0.9637\n",
            "Epoch 13/100\n",
            "638/638 [==============================] - ETA: 0s - loss: 0.2743 - accuracy: 0.9246 - precision_3: 0.9083 - recall_3: 0.9446\n",
            "Epoch 13: val_loss did not improve from 0.26398\n",
            "638/638 [==============================] - 260s 407ms/step - loss: 0.2743 - accuracy: 0.9246 - precision_3: 0.9083 - recall_3: 0.9446 - val_loss: 0.2703 - val_accuracy: 0.9264 - val_precision_3: 0.9002 - val_recall_3: 0.9590\n",
            "Epoch 14/100\n",
            "638/638 [==============================] - ETA: 0s - loss: 0.2736 - accuracy: 0.9248 - precision_3: 0.9087 - recall_3: 0.9446\n",
            "Epoch 14: val_loss did not improve from 0.26398\n",
            "638/638 [==============================] - 256s 402ms/step - loss: 0.2736 - accuracy: 0.9248 - precision_3: 0.9087 - recall_3: 0.9446 - val_loss: 0.2714 - val_accuracy: 0.9275 - val_precision_3: 0.8997 - val_recall_3: 0.9622\n",
            "Epoch 15/100\n",
            "638/638 [==============================] - ETA: 0s - loss: 0.2756 - accuracy: 0.9247 - precision_3: 0.9090 - recall_3: 0.9438\n",
            "Epoch 15: val_loss did not improve from 0.26398\n",
            "638/638 [==============================] - 258s 404ms/step - loss: 0.2756 - accuracy: 0.9247 - precision_3: 0.9090 - recall_3: 0.9438 - val_loss: 0.2650 - val_accuracy: 0.9310 - val_precision_3: 0.9086 - val_recall_3: 0.9584\n",
            "Epoch 16/100\n",
            "638/638 [==============================] - ETA: 0s - loss: 0.2709 - accuracy: 0.9252 - precision_3: 0.9108 - recall_3: 0.9428\n",
            "Epoch 16: val_loss did not improve from 0.26398\n",
            "638/638 [==============================] - 258s 405ms/step - loss: 0.2709 - accuracy: 0.9252 - precision_3: 0.9108 - recall_3: 0.9428 - val_loss: 0.2679 - val_accuracy: 0.9281 - val_precision_3: 0.9023 - val_recall_3: 0.9602\n",
            "Epoch 17/100\n",
            "638/638 [==============================] - ETA: 0s - loss: 0.2703 - accuracy: 0.9255 - precision_3: 0.9102 - recall_3: 0.9442\n",
            "Epoch 17: val_loss improved from 0.26398 to 0.25886, saving model to models/best_html_model3.keras\n",
            "638/638 [==============================] - 260s 407ms/step - loss: 0.2703 - accuracy: 0.9255 - precision_3: 0.9102 - recall_3: 0.9442 - val_loss: 0.2589 - val_accuracy: 0.9331 - val_precision_3: 0.9143 - val_recall_3: 0.9559\n",
            "Epoch 18/100\n",
            "638/638 [==============================] - ETA: 0s - loss: 0.2659 - accuracy: 0.9270 - precision_3: 0.9132 - recall_3: 0.9437\n",
            "Epoch 18: val_loss did not improve from 0.25886\n",
            "638/638 [==============================] - 253s 397ms/step - loss: 0.2659 - accuracy: 0.9270 - precision_3: 0.9132 - recall_3: 0.9437 - val_loss: 0.2594 - val_accuracy: 0.9313 - val_precision_3: 0.9095 - val_recall_3: 0.9578\n",
            "Epoch 19/100\n",
            "638/638 [==============================] - ETA: 0s - loss: 0.2656 - accuracy: 0.9271 - precision_3: 0.9131 - recall_3: 0.9441\n",
            "Epoch 19: val_loss did not improve from 0.25886\n",
            "638/638 [==============================] - 253s 397ms/step - loss: 0.2656 - accuracy: 0.9271 - precision_3: 0.9131 - recall_3: 0.9441 - val_loss: 0.2590 - val_accuracy: 0.9311 - val_precision_3: 0.9066 - val_recall_3: 0.9612\n",
            "Epoch 20/100\n",
            "638/638 [==============================] - ETA: 0s - loss: 0.2635 - accuracy: 0.9276 - precision_3: 0.9135 - recall_3: 0.9445\n",
            "Epoch 20: val_loss improved from 0.25886 to 0.25683, saving model to models/best_html_model3.keras\n",
            "638/638 [==============================] - 254s 398ms/step - loss: 0.2635 - accuracy: 0.9276 - precision_3: 0.9135 - recall_3: 0.9445 - val_loss: 0.2568 - val_accuracy: 0.9303 - val_precision_3: 0.9066 - val_recall_3: 0.9594\n",
            "Epoch 21/100\n",
            "638/638 [==============================] - ETA: 0s - loss: 0.2659 - accuracy: 0.9274 - precision_3: 0.9134 - recall_3: 0.9443\n",
            "Epoch 21: val_loss improved from 0.25683 to 0.25627, saving model to models/best_html_model3.keras\n",
            "638/638 [==============================] - 255s 400ms/step - loss: 0.2659 - accuracy: 0.9274 - precision_3: 0.9134 - recall_3: 0.9443 - val_loss: 0.2563 - val_accuracy: 0.9330 - val_precision_3: 0.9124 - val_recall_3: 0.9580\n",
            "Epoch 22/100\n",
            "638/638 [==============================] - ETA: 0s - loss: 0.2652 - accuracy: 0.9280 - precision_3: 0.9142 - recall_3: 0.9445\n",
            "Epoch 22: val_loss improved from 0.25627 to 0.25061, saving model to models/best_html_model3.keras\n",
            "638/638 [==============================] - 252s 396ms/step - loss: 0.2652 - accuracy: 0.9280 - precision_3: 0.9142 - recall_3: 0.9445 - val_loss: 0.2506 - val_accuracy: 0.9323 - val_precision_3: 0.9114 - val_recall_3: 0.9576\n",
            "Epoch 23/100\n",
            "638/638 [==============================] - ETA: 0s - loss: 0.2639 - accuracy: 0.9270 - precision_3: 0.9139 - recall_3: 0.9428\n",
            "Epoch 23: val_loss did not improve from 0.25061\n",
            "638/638 [==============================] - 254s 398ms/step - loss: 0.2639 - accuracy: 0.9270 - precision_3: 0.9139 - recall_3: 0.9428 - val_loss: 0.2628 - val_accuracy: 0.9282 - val_precision_3: 0.9043 - val_recall_3: 0.9578\n",
            "Epoch 24/100\n",
            "638/638 [==============================] - ETA: 0s - loss: 0.2591 - accuracy: 0.9290 - precision_3: 0.9167 - recall_3: 0.9438\n",
            "Epoch 24: val_loss did not improve from 0.25061\n",
            "638/638 [==============================] - 256s 401ms/step - loss: 0.2591 - accuracy: 0.9290 - precision_3: 0.9167 - recall_3: 0.9438 - val_loss: 0.2580 - val_accuracy: 0.9320 - val_precision_3: 0.9080 - val_recall_3: 0.9614\n",
            "Epoch 25/100\n",
            "638/638 [==============================] - ETA: 0s - loss: 0.2614 - accuracy: 0.9285 - precision_3: 0.9161 - recall_3: 0.9434\n",
            "Epoch 25: val_loss did not improve from 0.25061\n",
            "638/638 [==============================] - 257s 403ms/step - loss: 0.2614 - accuracy: 0.9285 - precision_3: 0.9161 - recall_3: 0.9434 - val_loss: 0.2522 - val_accuracy: 0.9345 - val_precision_3: 0.9151 - val_recall_3: 0.9578\n",
            "Epoch 26/100\n",
            "638/638 [==============================] - ETA: 0s - loss: 0.2605 - accuracy: 0.9298 - precision_3: 0.9167 - recall_3: 0.9455\n",
            "Epoch 26: val_loss did not improve from 0.25061\n",
            "638/638 [==============================] - 258s 404ms/step - loss: 0.2605 - accuracy: 0.9298 - precision_3: 0.9167 - recall_3: 0.9455 - val_loss: 0.2620 - val_accuracy: 0.9302 - val_precision_3: 0.9043 - val_recall_3: 0.9622\n",
            "Epoch 27/100\n",
            "638/638 [==============================] - ETA: 0s - loss: 0.2612 - accuracy: 0.9298 - precision_3: 0.9171 - recall_3: 0.9449\n",
            "Epoch 27: val_loss did not improve from 0.25061\n",
            "Restoring model weights from the end of the best epoch: 22.\n",
            "638/638 [==============================] - 257s 402ms/step - loss: 0.2612 - accuracy: 0.9298 - precision_3: 0.9171 - recall_3: 0.9449 - val_loss: 0.2542 - val_accuracy: 0.9346 - val_precision_3: 0.9164 - val_recall_3: 0.9565\n",
            "Epoch 27: early stopping\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Evaluate model"
      ],
      "metadata": {
        "id": "B8ZKmubldoTr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "best_html_model3 = keras.models.load_model(\n",
        "    'models/best_html_model3.keras',\n",
        "    custom_objects={'GCNConv': GCNConv,\n",
        "                    'GlobalSumPool': GlobalSumPool,\n",
        "                    'GCN': GCN})"
      ],
      "metadata": {
        "id": "hy57R1qCeAOe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "results = best_html_model3.evaluate(html_test_dataset, verbose=1)\n",
        "precision = results[2]\n",
        "recall = results[3]\n",
        "f1_score = 2 * (precision * recall) / (precision + recall)\n",
        "print(f\"F1-Score: {f1_score:.4f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0N9CIv-leChT",
        "outputId": "f9eed645-d4d5-4f62-aafd-7436c095587f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "80/80 [==============================] - 14s 172ms/step - loss: 0.2601 - accuracy: 0.9248 - precision_3: 0.9035 - recall_3: 0.9512\n",
            "F1-Score: 0.9267\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Experiment 4**"
      ],
      "metadata": {
        "id": "W5yd8yIP_FZv"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Train model"
      ],
      "metadata": {
        "id": "wzmazo8X_JRb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def create_html_model(max_nodes, feature_dim, gcn_units,\n",
        "                      num_gcn_layers=1, dense_dim=128):\n",
        "    inputs_adj = keras.Input(shape=(max_nodes, max_nodes), dtype=tf.float32)\n",
        "    inputs_feat = keras.Input(shape=(max_nodes, feature_dim), dtype=tf.float32)\n",
        "\n",
        "    x = inputs_feat\n",
        "    for _ in range(num_gcn_layers):\n",
        "        x = GCN(gcn_units, activation='relu')([x, inputs_adj])\n",
        "    x = GlobalSumPool()(x)\n",
        "    x = layers.Dense(dense_dim, activation='relu')(x)\n",
        "    outputs = layers.Dense(1, activation='sigmoid')(x)\n",
        "    html_model = keras.Model(inputs=[inputs_adj, inputs_feat], outputs=outputs)\n",
        "\n",
        "    return html_model"
      ],
      "metadata": {
        "id": "kkb4h81u_Ln1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = create_html_model(max_nodes=max_nodes,\n",
        "                          feature_dim=feature_dim,\n",
        "                          gcn_units=128,\n",
        "                          num_gcn_layers=2,\n",
        "                          dense_dim=128)\n",
        "\n",
        "model.summary()\n",
        "\n",
        "optimizer = keras.optimizers.Adam(learning_rate=1e-3)\n",
        "metrics = ['accuracy', tf.keras.metrics.Precision(), tf.keras.metrics.Recall()]\n",
        "model.compile(optimizer=optimizer, loss='binary_crossentropy', metrics=metrics)\n",
        "\n",
        "checkpoint_filepath = 'models/best_html_model4.keras'\n",
        "\n",
        "checkpoint_callback = tf.keras.callbacks.ModelCheckpoint(\n",
        "    filepath=checkpoint_filepath,\n",
        "    save_weights_only=False,\n",
        "    monitor='val_loss',\n",
        "    mode='min',\n",
        "    save_best_only=True,\n",
        "    verbose=1\n",
        ")\n",
        "\n",
        "early_stopping = tf.keras.callbacks.EarlyStopping(\n",
        "    monitor='val_loss',\n",
        "    patience=5,\n",
        "    restore_best_weights=True,\n",
        "    verbose=1\n",
        ")\n",
        "\n",
        "history = model.fit(html_train_dataset,\n",
        "                    validation_data=html_val_dataset,\n",
        "                    epochs=100,\n",
        "                    callbacks=[checkpoint_callback, early_stopping])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Yc9rlVil_aK6",
        "outputId": "a451339d-ef0a-48fa-f4dc-143342d93fa5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"model\"\n",
            "__________________________________________________________________________________________________\n",
            " Layer (type)                Output Shape                 Param #   Connected to                  \n",
            "==================================================================================================\n",
            " input_2 (InputLayer)        [(None, 600, 3)]             0         []                            \n",
            "                                                                                                  \n",
            " input_1 (InputLayer)        [(None, 600, 600)]           0         []                            \n",
            "                                                                                                  \n",
            " gcn (GCN)                   (None, 600, 128)             512       ['input_2[0][0]',             \n",
            "                                                                     'input_1[0][0]']             \n",
            "                                                                                                  \n",
            " gcn_1 (GCN)                 (None, 600, 128)             16512     ['gcn[0][0]',                 \n",
            "                                                                     'input_1[0][0]']             \n",
            "                                                                                                  \n",
            " global_sum_pool (GlobalSum  (None, 128)                  0         ['gcn_1[0][0]']               \n",
            " Pool)                                                                                            \n",
            "                                                                                                  \n",
            " dense (Dense)               (None, 128)                  16512     ['global_sum_pool[0][0]']     \n",
            "                                                                                                  \n",
            " dense_1 (Dense)             (None, 1)                    129       ['dense[0][0]']               \n",
            "                                                                                                  \n",
            "==================================================================================================\n",
            "Total params: 33665 (131.50 KB)\n",
            "Trainable params: 33665 (131.50 KB)\n",
            "Non-trainable params: 0 (0.00 Byte)\n",
            "__________________________________________________________________________________________________\n",
            "Epoch 1/100\n",
            "638/638 [==============================] - ETA: 0s - loss: 0.3187 - accuracy: 0.8823 - precision: 0.8463 - recall: 0.9342\n",
            "Epoch 1: val_loss improved from inf to 0.26855, saving model to models/best_html_model4.keras\n",
            "638/638 [==============================] - 251s 391ms/step - loss: 0.3187 - accuracy: 0.8823 - precision: 0.8463 - recall: 0.9342 - val_loss: 0.2685 - val_accuracy: 0.8967 - val_precision: 0.8658 - val_recall: 0.9388\n",
            "Epoch 2/100\n",
            "638/638 [==============================] - ETA: 0s - loss: 0.2652 - accuracy: 0.8987 - precision: 0.8684 - recall: 0.9397\n",
            "Epoch 2: val_loss improved from 0.26855 to 0.25565, saving model to models/best_html_model4.keras\n",
            "638/638 [==============================] - 237s 372ms/step - loss: 0.2652 - accuracy: 0.8987 - precision: 0.8684 - recall: 0.9397 - val_loss: 0.2556 - val_accuracy: 0.8954 - val_precision: 0.8651 - val_recall: 0.9369\n",
            "Epoch 3/100\n",
            "638/638 [==============================] - ETA: 0s - loss: 0.2485 - accuracy: 0.9058 - precision: 0.8813 - recall: 0.9379\n",
            "Epoch 3: val_loss improved from 0.25565 to 0.24681, saving model to models/best_html_model4.keras\n",
            "638/638 [==============================] - 236s 369ms/step - loss: 0.2485 - accuracy: 0.9058 - precision: 0.8813 - recall: 0.9379 - val_loss: 0.2468 - val_accuracy: 0.9061 - val_precision: 0.8792 - val_recall: 0.9416\n",
            "Epoch 4/100\n",
            "638/638 [==============================] - ETA: 0s - loss: 0.2372 - accuracy: 0.9101 - precision: 0.8908 - recall: 0.9349\n",
            "Epoch 4: val_loss improved from 0.24681 to 0.23115, saving model to models/best_html_model4.keras\n",
            "638/638 [==============================] - 236s 370ms/step - loss: 0.2372 - accuracy: 0.9101 - precision: 0.8908 - recall: 0.9349 - val_loss: 0.2311 - val_accuracy: 0.9126 - val_precision: 0.8895 - val_recall: 0.9424\n",
            "Epoch 5/100\n",
            "638/638 [==============================] - ETA: 0s - loss: 0.2292 - accuracy: 0.9136 - precision: 0.8970 - recall: 0.9346\n",
            "Epoch 5: val_loss improved from 0.23115 to 0.22341, saving model to models/best_html_model4.keras\n",
            "638/638 [==============================] - 236s 369ms/step - loss: 0.2292 - accuracy: 0.9136 - precision: 0.8970 - recall: 0.9346 - val_loss: 0.2234 - val_accuracy: 0.9155 - val_precision: 0.8945 - val_recall: 0.9422\n",
            "Epoch 6/100\n",
            "638/638 [==============================] - ETA: 0s - loss: 0.2226 - accuracy: 0.9157 - precision: 0.9013 - recall: 0.9338\n",
            "Epoch 6: val_loss improved from 0.22341 to 0.21631, saving model to models/best_html_model4.keras\n",
            "638/638 [==============================] - 235s 369ms/step - loss: 0.2226 - accuracy: 0.9157 - precision: 0.9013 - recall: 0.9338 - val_loss: 0.2163 - val_accuracy: 0.9175 - val_precision: 0.8959 - val_recall: 0.9449\n",
            "Epoch 7/100\n",
            "638/638 [==============================] - ETA: 0s - loss: 0.2164 - accuracy: 0.9176 - precision: 0.9045 - recall: 0.9337\n",
            "Epoch 7: val_loss improved from 0.21631 to 0.21028, saving model to models/best_html_model4.keras\n",
            "638/638 [==============================] - 237s 371ms/step - loss: 0.2164 - accuracy: 0.9176 - precision: 0.9045 - recall: 0.9337 - val_loss: 0.2103 - val_accuracy: 0.9218 - val_precision: 0.9063 - val_recall: 0.9408\n",
            "Epoch 8/100\n",
            "638/638 [==============================] - ETA: 0s - loss: 0.2114 - accuracy: 0.9197 - precision: 0.9077 - recall: 0.9345\n",
            "Epoch 8: val_loss improved from 0.21028 to 0.20309, saving model to models/best_html_model4.keras\n",
            "638/638 [==============================] - 229s 360ms/step - loss: 0.2114 - accuracy: 0.9197 - precision: 0.9077 - recall: 0.9345 - val_loss: 0.2031 - val_accuracy: 0.9235 - val_precision: 0.9068 - val_recall: 0.9441\n",
            "Epoch 9/100\n",
            "638/638 [==============================] - ETA: 0s - loss: 0.2055 - accuracy: 0.9220 - precision: 0.9109 - recall: 0.9355\n",
            "Epoch 9: val_loss improved from 0.20309 to 0.20085, saving model to models/best_html_model4.keras\n",
            "638/638 [==============================] - 233s 365ms/step - loss: 0.2055 - accuracy: 0.9220 - precision: 0.9109 - recall: 0.9355 - val_loss: 0.2008 - val_accuracy: 0.9239 - val_precision: 0.9078 - val_recall: 0.9437\n",
            "Epoch 10/100\n",
            "638/638 [==============================] - ETA: 0s - loss: 0.2020 - accuracy: 0.9229 - precision: 0.9124 - recall: 0.9356\n",
            "Epoch 10: val_loss improved from 0.20085 to 0.19776, saving model to models/best_html_model4.keras\n",
            "638/638 [==============================] - 233s 365ms/step - loss: 0.2020 - accuracy: 0.9229 - precision: 0.9124 - recall: 0.9356 - val_loss: 0.1978 - val_accuracy: 0.9235 - val_precision: 0.9033 - val_recall: 0.9486\n",
            "Epoch 11/100\n",
            "638/638 [==============================] - ETA: 0s - loss: 0.1978 - accuracy: 0.9250 - precision: 0.9152 - recall: 0.9368\n",
            "Epoch 11: val_loss did not improve from 0.19776\n",
            "638/638 [==============================] - 231s 361ms/step - loss: 0.1978 - accuracy: 0.9250 - precision: 0.9152 - recall: 0.9368 - val_loss: 0.1988 - val_accuracy: 0.9229 - val_precision: 0.9009 - val_recall: 0.9504\n",
            "Epoch 12/100\n",
            "638/638 [==============================] - ETA: 0s - loss: 0.1946 - accuracy: 0.9261 - precision: 0.9171 - recall: 0.9369\n",
            "Epoch 12: val_loss did not improve from 0.19776\n",
            "638/638 [==============================] - 229s 359ms/step - loss: 0.1946 - accuracy: 0.9261 - precision: 0.9171 - recall: 0.9369 - val_loss: 0.1990 - val_accuracy: 0.9230 - val_precision: 0.8986 - val_recall: 0.9537\n",
            "Epoch 13/100\n",
            "638/638 [==============================] - ETA: 0s - loss: 0.1911 - accuracy: 0.9273 - precision: 0.9193 - recall: 0.9369\n",
            "Epoch 13: val_loss improved from 0.19776 to 0.19652, saving model to models/best_html_model4.keras\n",
            "638/638 [==============================] - 230s 360ms/step - loss: 0.1911 - accuracy: 0.9273 - precision: 0.9193 - recall: 0.9369 - val_loss: 0.1965 - val_accuracy: 0.9227 - val_precision: 0.8984 - val_recall: 0.9533\n",
            "Epoch 14/100\n",
            "638/638 [==============================] - ETA: 0s - loss: 0.1881 - accuracy: 0.9286 - precision: 0.9209 - recall: 0.9378\n",
            "Epoch 14: val_loss did not improve from 0.19652\n",
            "638/638 [==============================] - 230s 361ms/step - loss: 0.1881 - accuracy: 0.9286 - precision: 0.9209 - recall: 0.9378 - val_loss: 0.1972 - val_accuracy: 0.9228 - val_precision: 0.8968 - val_recall: 0.9557\n",
            "Epoch 15/100\n",
            "638/638 [==============================] - ETA: 0s - loss: 0.1850 - accuracy: 0.9295 - precision: 0.9228 - recall: 0.9374\n",
            "Epoch 15: val_loss improved from 0.19652 to 0.19546, saving model to models/best_html_model4.keras\n",
            "638/638 [==============================] - 227s 356ms/step - loss: 0.1850 - accuracy: 0.9295 - precision: 0.9228 - recall: 0.9374 - val_loss: 0.1955 - val_accuracy: 0.9242 - val_precision: 0.8994 - val_recall: 0.9553\n",
            "Epoch 16/100\n",
            "638/638 [==============================] - ETA: 0s - loss: 0.1823 - accuracy: 0.9303 - precision: 0.9242 - recall: 0.9375\n",
            "Epoch 16: val_loss improved from 0.19546 to 0.19242, saving model to models/best_html_model4.keras\n",
            "638/638 [==============================] - 229s 360ms/step - loss: 0.1823 - accuracy: 0.9303 - precision: 0.9242 - recall: 0.9375 - val_loss: 0.1924 - val_accuracy: 0.9260 - val_precision: 0.9037 - val_recall: 0.9535\n",
            "Epoch 17/100\n",
            "638/638 [==============================] - ETA: 0s - loss: 0.1802 - accuracy: 0.9313 - precision: 0.9260 - recall: 0.9375\n",
            "Epoch 17: val_loss did not improve from 0.19242\n",
            "638/638 [==============================] - 230s 360ms/step - loss: 0.1802 - accuracy: 0.9313 - precision: 0.9260 - recall: 0.9375 - val_loss: 0.1950 - val_accuracy: 0.9242 - val_precision: 0.8992 - val_recall: 0.9555\n",
            "Epoch 18/100\n",
            "638/638 [==============================] - ETA: 0s - loss: 0.1782 - accuracy: 0.9320 - precision: 0.9273 - recall: 0.9376\n",
            "Epoch 18: val_loss improved from 0.19242 to 0.19238, saving model to models/best_html_model4.keras\n",
            "638/638 [==============================] - 230s 360ms/step - loss: 0.1782 - accuracy: 0.9320 - precision: 0.9273 - recall: 0.9376 - val_loss: 0.1924 - val_accuracy: 0.9253 - val_precision: 0.9009 - val_recall: 0.9557\n",
            "Epoch 19/100\n",
            "638/638 [==============================] - ETA: 0s - loss: 0.1766 - accuracy: 0.9326 - precision: 0.9283 - recall: 0.9376\n",
            "Epoch 19: val_loss did not improve from 0.19238\n",
            "638/638 [==============================] - 230s 360ms/step - loss: 0.1766 - accuracy: 0.9326 - precision: 0.9283 - recall: 0.9376 - val_loss: 0.1941 - val_accuracy: 0.9239 - val_precision: 0.8987 - val_recall: 0.9555\n",
            "Epoch 20/100\n",
            "638/638 [==============================] - ETA: 0s - loss: 0.1748 - accuracy: 0.9339 - precision: 0.9300 - recall: 0.9384\n",
            "Epoch 20: val_loss did not improve from 0.19238\n",
            "638/638 [==============================] - 228s 357ms/step - loss: 0.1748 - accuracy: 0.9339 - precision: 0.9300 - recall: 0.9384 - val_loss: 0.1937 - val_accuracy: 0.9263 - val_precision: 0.9027 - val_recall: 0.9555\n",
            "Epoch 21/100\n",
            "638/638 [==============================] - ETA: 0s - loss: 0.1732 - accuracy: 0.9338 - precision: 0.9303 - recall: 0.9379\n",
            "Epoch 21: val_loss improved from 0.19238 to 0.19177, saving model to models/best_html_model4.keras\n",
            "638/638 [==============================] - 229s 360ms/step - loss: 0.1732 - accuracy: 0.9338 - precision: 0.9303 - recall: 0.9379 - val_loss: 0.1918 - val_accuracy: 0.9252 - val_precision: 0.9009 - val_recall: 0.9555\n",
            "Epoch 22/100\n",
            "638/638 [==============================] - ETA: 0s - loss: 0.1719 - accuracy: 0.9349 - precision: 0.9318 - recall: 0.9385\n",
            "Epoch 22: val_loss did not improve from 0.19177\n",
            "638/638 [==============================] - 229s 360ms/step - loss: 0.1719 - accuracy: 0.9349 - precision: 0.9318 - recall: 0.9385 - val_loss: 0.1966 - val_accuracy: 0.9235 - val_precision: 0.8957 - val_recall: 0.9586\n",
            "Epoch 23/100\n",
            "638/638 [==============================] - ETA: 0s - loss: 0.1696 - accuracy: 0.9354 - precision: 0.9327 - recall: 0.9386\n",
            "Epoch 23: val_loss improved from 0.19177 to 0.18924, saving model to models/best_html_model4.keras\n",
            "638/638 [==============================] - 230s 360ms/step - loss: 0.1696 - accuracy: 0.9354 - precision: 0.9327 - recall: 0.9386 - val_loss: 0.1892 - val_accuracy: 0.9261 - val_precision: 0.9026 - val_recall: 0.9553\n",
            "Epoch 24/100\n",
            "638/638 [==============================] - ETA: 0s - loss: 0.1682 - accuracy: 0.9357 - precision: 0.9331 - recall: 0.9388\n",
            "Epoch 24: val_loss did not improve from 0.18924\n",
            "638/638 [==============================] - 228s 358ms/step - loss: 0.1682 - accuracy: 0.9357 - precision: 0.9331 - recall: 0.9388 - val_loss: 0.1953 - val_accuracy: 0.9237 - val_precision: 0.8958 - val_recall: 0.9590\n",
            "Epoch 25/100\n",
            "638/638 [==============================] - ETA: 0s - loss: 0.1668 - accuracy: 0.9369 - precision: 0.9345 - recall: 0.9396\n",
            "Epoch 25: val_loss did not improve from 0.18924\n",
            "638/638 [==============================] - 228s 358ms/step - loss: 0.1668 - accuracy: 0.9369 - precision: 0.9345 - recall: 0.9396 - val_loss: 0.1949 - val_accuracy: 0.9265 - val_precision: 0.9004 - val_recall: 0.9590\n",
            "Epoch 26/100\n",
            "638/638 [==============================] - ETA: 0s - loss: 0.1653 - accuracy: 0.9377 - precision: 0.9352 - recall: 0.9404\n",
            "Epoch 26: val_loss did not improve from 0.18924\n",
            "638/638 [==============================] - 226s 354ms/step - loss: 0.1653 - accuracy: 0.9377 - precision: 0.9352 - recall: 0.9404 - val_loss: 0.1913 - val_accuracy: 0.9274 - val_precision: 0.9025 - val_recall: 0.9582\n",
            "Epoch 27/100\n",
            "638/638 [==============================] - ETA: 0s - loss: 0.1651 - accuracy: 0.9373 - precision: 0.9348 - recall: 0.9402\n",
            "Epoch 27: val_loss did not improve from 0.18924\n",
            "638/638 [==============================] - 229s 359ms/step - loss: 0.1651 - accuracy: 0.9373 - precision: 0.9348 - recall: 0.9402 - val_loss: 0.2005 - val_accuracy: 0.9265 - val_precision: 0.8992 - val_recall: 0.9606\n",
            "Epoch 28/100\n",
            "638/638 [==============================] - ETA: 0s - loss: 0.1638 - accuracy: 0.9379 - precision: 0.9361 - recall: 0.9399\n",
            "Epoch 28: val_loss did not improve from 0.18924\n",
            "Restoring model weights from the end of the best epoch: 23.\n",
            "638/638 [==============================] - 226s 354ms/step - loss: 0.1638 - accuracy: 0.9379 - precision: 0.9361 - recall: 0.9399 - val_loss: 0.2034 - val_accuracy: 0.9242 - val_precision: 0.8950 - val_recall: 0.9612\n",
            "Epoch 28: early stopping\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Evaluate model"
      ],
      "metadata": {
        "id": "qZdZB5kA_xg_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "best_html_model4 = keras.models.load_model(\n",
        "    'models/best_html_model4.keras',\n",
        "    custom_objects={'GCNConv': GCNConv,\n",
        "                    'GlobalSumPool': GlobalSumPool,\n",
        "                    'GCN': GCN})"
      ],
      "metadata": {
        "id": "1QGl9_Qz_0j5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "results = best_html_model4.evaluate(html_test_dataset, verbose=1)\n",
        "precision = results[2]\n",
        "recall = results[3]\n",
        "f1_score = 2 * (precision * recall) / (precision + recall)\n",
        "print(f\"F1-Score: {f1_score:.4f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_h5htQw4_29_",
        "outputId": "92f97e84-f15f-4fad-c431-ff9c8053051b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "80/80 [==============================] - 25s 185ms/step - loss: 0.1888 - accuracy: 0.9256 - precision: 0.9049 - recall: 0.9512\n",
            "F1-Score: 0.9274\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Experiment 5**"
      ],
      "metadata": {
        "id": "5siGBHaSd6mg"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Train model"
      ],
      "metadata": {
        "id": "OX3_rptwd_Rc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from utils.layers import PositionalEmbedding, TransformerEncoder"
      ],
      "metadata": {
        "id": "QKePFPsgem1h"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def create_url_model(vocab_size, max_words, embed_dim,\n",
        "                     num_heads, intermediate_dim,\n",
        "                     num_transformer_layers=1):\n",
        "    inputs = keras.Input(shape=(max_words,), dtype=tf.int32)\n",
        "    x = PositionalEmbedding(max_words, vocab_size, embed_dim)(inputs)\n",
        "    for _ in range(num_transformer_layers):\n",
        "        x = TransformerEncoder(embed_dim, num_heads, intermediate_dim)(x)\n",
        "    x = layers.GlobalAveragePooling1D()(x)\n",
        "    url_model = keras.Model(inputs=inputs, outputs=x)\n",
        "\n",
        "    return url_model"
      ],
      "metadata": {
        "id": "sD56ioeDeDLA"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def create_html_model(max_nodes, feature_dim,\n",
        "                      gcn_units, num_gcn_layers=1):\n",
        "    inputs_adj = keras.Input(shape=(max_nodes, max_nodes), dtype=tf.float32)\n",
        "    inputs_feat = keras.Input(shape=(max_nodes, feature_dim), dtype=tf.float32)\n",
        "\n",
        "    x = inputs_feat\n",
        "    for _ in range(num_gcn_layers):\n",
        "        x = GCN(gcn_units, activation='relu')([x, inputs_adj])\n",
        "    x = GlobalSumPool()(x)\n",
        "    html_model = keras.Model(inputs=[inputs_adj, inputs_feat], outputs=x)\n",
        "\n",
        "    return html_model"
      ],
      "metadata": {
        "id": "yO4WKjRBhScT"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def create_full_model(vocab_size, max_words, embed_dim, num_heads,\n",
        "                      intermediate_dim, num_transformer_layers,\n",
        "                      max_nodes, feature_dim, gcn_units,\n",
        "                      num_gcn_layers, dense_dim):\n",
        "    # URL Model\n",
        "    url_model = create_url_model(vocab_size, max_words, embed_dim, num_heads,\n",
        "                                 intermediate_dim, num_transformer_layers)\n",
        "    url_model.summary()\n",
        "\n",
        "    # HTML Model\n",
        "    html_model = create_html_model(max_nodes, feature_dim,\n",
        "                                   gcn_units, num_gcn_layers)\n",
        "    html_model.summary()\n",
        "\n",
        "    # Inputs\n",
        "    url_inputs = keras.Input(shape=(max_words,), dtype=tf.int32)\n",
        "    adj_inputs = keras.Input(shape=(max_nodes, max_nodes), dtype=tf.float64)\n",
        "    feat_inputs = keras.Input(shape=(max_nodes, feature_dim), dtype=tf.float64)\n",
        "\n",
        "    # Outputs from both models\n",
        "    url_output = url_model(url_inputs)  # (None, embed_dim)\n",
        "    html_output = html_model([adj_inputs, feat_inputs])  # (None, gcn_units)\n",
        "\n",
        "    # Concatenate the outputs (both are 2D now)\n",
        "    combined = layers.Concatenate()([url_output, html_output])  # (None, embed_dim + gcn_units)\n",
        "\n",
        "    # Final layers\n",
        "    x = layers.Dense(dense_dim, activation='relu')(combined)\n",
        "\n",
        "    outputs = layers.Dense(1, activation='sigmoid')(x)\n",
        "\n",
        "    full_model = keras.Model(inputs=[url_inputs, adj_inputs, feat_inputs], outputs=outputs)\n",
        "    return full_model"
      ],
      "metadata": {
        "id": "qtZ-Co3_et02"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "vocab_size = 6000\n",
        "max_words = 50\n",
        "max_nodes = 600\n",
        "feature_dim = 3\n",
        "\n",
        "train_dataset = load_dataset('data/train.h5', batch_size=128)\n",
        "val_dataset = load_dataset('data/val.h5', batch_size=128)\n",
        "test_dataset = load_dataset('data/test.h5', batch_size=128)"
      ],
      "metadata": {
        "id": "eCKYtTYBfQEZ"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = create_full_model(vocab_size=vocab_size,\n",
        "                          max_words=max_words,\n",
        "                          embed_dim=128,\n",
        "                          num_heads=4,\n",
        "                          intermediate_dim=128,\n",
        "                          num_transformer_layers=2,\n",
        "                          max_nodes=max_nodes,\n",
        "                          feature_dim=feature_dim,\n",
        "                          gcn_units=128,\n",
        "                          num_gcn_layers=2,\n",
        "                          dense_dim=128)\n",
        "\n",
        "model.summary()\n",
        "\n",
        "optimizer = keras.optimizers.Adam(learning_rate=1e-3)\n",
        "metrics = ['accuracy', tf.keras.metrics.Precision(), tf.keras.metrics.Recall()]\n",
        "model.compile(optimizer=optimizer, loss='binary_crossentropy', metrics=metrics)\n",
        "\n",
        "checkpoint_filepath = 'models/best_model_5.keras'\n",
        "\n",
        "checkpoint_callback = tf.keras.callbacks.ModelCheckpoint(\n",
        "    filepath=checkpoint_filepath,\n",
        "    save_weights_only=False,\n",
        "    monitor='val_loss',\n",
        "    mode='min',\n",
        "    save_best_only=True,\n",
        "    verbose=1\n",
        ")\n",
        "\n",
        "early_stopping = tf.keras.callbacks.EarlyStopping(\n",
        "    monitor='val_loss',\n",
        "    patience=5,\n",
        "    restore_best_weights=True,\n",
        "    verbose=1\n",
        ")\n",
        "\n",
        "history = model.fit(train_dataset,\n",
        "                    validation_data=val_dataset,\n",
        "                    epochs=100,\n",
        "                    callbacks=[checkpoint_callback, early_stopping])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "91gfUGYZgfPK",
        "outputId": "a66ba1a3-e06e-4635-92a9-32a4e34a1eaf"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"model\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " input_1 (InputLayer)        [(None, 50)]              0         \n",
            "                                                                 \n",
            " positional_embedding (Posi  (None, 50, 128)           774400    \n",
            " tionalEmbedding)                                                \n",
            "                                                                 \n",
            " transformer_encoder (Trans  (None, 50, 128)           297344    \n",
            " formerEncoder)                                                  \n",
            "                                                                 \n",
            " transformer_encoder_1 (Tra  (None, 50, 128)           297344    \n",
            " nsformerEncoder)                                                \n",
            "                                                                 \n",
            " global_average_pooling1d (  (None, 128)               0         \n",
            " GlobalAveragePooling1D)                                         \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 1369088 (5.22 MB)\n",
            "Trainable params: 1369088 (5.22 MB)\n",
            "Non-trainable params: 0 (0.00 Byte)\n",
            "_________________________________________________________________\n",
            "Model: \"model_1\"\n",
            "__________________________________________________________________________________________________\n",
            " Layer (type)                Output Shape                 Param #   Connected to                  \n",
            "==================================================================================================\n",
            " input_3 (InputLayer)        [(None, 600, 3)]             0         []                            \n",
            "                                                                                                  \n",
            " input_2 (InputLayer)        [(None, 600, 600)]           0         []                            \n",
            "                                                                                                  \n",
            " gcn (GCN)                   (None, 600, 128)             512       ['input_3[0][0]',             \n",
            "                                                                     'input_2[0][0]']             \n",
            "                                                                                                  \n",
            " gcn_1 (GCN)                 (None, 600, 128)             16512     ['gcn[0][0]',                 \n",
            "                                                                     'input_2[0][0]']             \n",
            "                                                                                                  \n",
            " global_sum_pool (GlobalSum  (None, 128)                  0         ['gcn_1[0][0]']               \n",
            " Pool)                                                                                            \n",
            "                                                                                                  \n",
            "==================================================================================================\n",
            "Total params: 17024 (66.50 KB)\n",
            "Trainable params: 17024 (66.50 KB)\n",
            "Non-trainable params: 0 (0.00 Byte)\n",
            "__________________________________________________________________________________________________\n",
            "Model: \"model_2\"\n",
            "__________________________________________________________________________________________________\n",
            " Layer (type)                Output Shape                 Param #   Connected to                  \n",
            "==================================================================================================\n",
            " input_4 (InputLayer)        [(None, 50)]                 0         []                            \n",
            "                                                                                                  \n",
            " input_5 (InputLayer)        [(None, 600, 600)]           0         []                            \n",
            "                                                                                                  \n",
            " input_6 (InputLayer)        [(None, 600, 3)]             0         []                            \n",
            "                                                                                                  \n",
            " model (Functional)          (None, 128)                  1369088   ['input_4[0][0]']             \n",
            "                                                                                                  \n",
            " model_1 (Functional)        (None, 128)                  17024     ['input_5[0][0]',             \n",
            "                                                                     'input_6[0][0]']             \n",
            "                                                                                                  \n",
            " concatenate (Concatenate)   (None, 256)                  0         ['model[0][0]',               \n",
            "                                                                     'model_1[0][0]']             \n",
            "                                                                                                  \n",
            " dense_4 (Dense)             (None, 128)                  32896     ['concatenate[0][0]']         \n",
            "                                                                                                  \n",
            " dense_5 (Dense)             (None, 1)                    129       ['dense_4[0][0]']             \n",
            "                                                                                                  \n",
            "==================================================================================================\n",
            "Total params: 1419137 (5.41 MB)\n",
            "Trainable params: 1419137 (5.41 MB)\n",
            "Non-trainable params: 0 (0.00 Byte)\n",
            "__________________________________________________________________________________________________\n",
            "Epoch 1/100\n",
            "638/638 [==============================] - ETA: 0s - loss: 0.1286 - accuracy: 0.9602 - precision: 0.9669 - recall: 0.9531\n",
            "Epoch 1: val_loss improved from inf to 0.06632, saving model to models/best_model_5.keras\n",
            "638/638 [==============================] - 319s 493ms/step - loss: 0.1286 - accuracy: 0.9602 - precision: 0.9669 - recall: 0.9531 - val_loss: 0.0663 - val_accuracy: 0.9795 - val_precision: 0.9872 - val_recall: 0.9716\n",
            "Epoch 2/100\n",
            "638/638 [==============================] - ETA: 0s - loss: 0.0664 - accuracy: 0.9801 - precision: 0.9902 - recall: 0.9699\n",
            "Epoch 2: val_loss improved from 0.06632 to 0.06413, saving model to models/best_model_5.keras\n",
            "638/638 [==============================] - 304s 476ms/step - loss: 0.0664 - accuracy: 0.9801 - precision: 0.9902 - recall: 0.9699 - val_loss: 0.0641 - val_accuracy: 0.9811 - val_precision: 0.9850 - val_recall: 0.9771\n",
            "Epoch 3/100\n",
            "638/638 [==============================] - ETA: 0s - loss: 0.0578 - accuracy: 0.9827 - precision: 0.9916 - recall: 0.9737\n",
            "Epoch 3: val_loss did not improve from 0.06413\n",
            "638/638 [==============================] - 303s 476ms/step - loss: 0.0578 - accuracy: 0.9827 - precision: 0.9916 - recall: 0.9737 - val_loss: 0.0719 - val_accuracy: 0.9795 - val_precision: 0.9805 - val_recall: 0.9784\n",
            "Epoch 4/100\n",
            "638/638 [==============================] - ETA: 0s - loss: 0.0546 - accuracy: 0.9838 - precision: 0.9923 - recall: 0.9752\n",
            "Epoch 4: val_loss did not improve from 0.06413\n",
            "638/638 [==============================] - 302s 474ms/step - loss: 0.0546 - accuracy: 0.9838 - precision: 0.9923 - recall: 0.9752 - val_loss: 0.0835 - val_accuracy: 0.9761 - val_precision: 0.9707 - val_recall: 0.9818\n",
            "Epoch 5/100\n",
            "638/638 [==============================] - ETA: 0s - loss: 0.0546 - accuracy: 0.9835 - precision: 0.9918 - recall: 0.9750\n",
            "Epoch 5: val_loss did not improve from 0.06413\n",
            "638/638 [==============================] - 303s 475ms/step - loss: 0.0546 - accuracy: 0.9835 - precision: 0.9918 - recall: 0.9750 - val_loss: 0.0751 - val_accuracy: 0.9784 - val_precision: 0.9762 - val_recall: 0.9808\n",
            "Epoch 6/100\n",
            "638/638 [==============================] - ETA: 0s - loss: 0.0494 - accuracy: 0.9851 - precision: 0.9927 - recall: 0.9774\n",
            "Epoch 6: val_loss did not improve from 0.06413\n",
            "638/638 [==============================] - 303s 474ms/step - loss: 0.0494 - accuracy: 0.9851 - precision: 0.9927 - recall: 0.9774 - val_loss: 0.0806 - val_accuracy: 0.9756 - val_precision: 0.9683 - val_recall: 0.9833\n",
            "Epoch 7/100\n",
            "638/638 [==============================] - ETA: 0s - loss: 0.0469 - accuracy: 0.9857 - precision: 0.9933 - recall: 0.9780\n",
            "Epoch 7: val_loss did not improve from 0.06413\n",
            "Restoring model weights from the end of the best epoch: 2.\n",
            "638/638 [==============================] - 302s 474ms/step - loss: 0.0469 - accuracy: 0.9857 - precision: 0.9933 - recall: 0.9780 - val_loss: 0.0755 - val_accuracy: 0.9780 - val_precision: 0.9749 - val_recall: 0.9814\n",
            "Epoch 7: early stopping\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Evaluate model"
      ],
      "metadata": {
        "id": "6f-9C8-phxHV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "best_model_5 = keras.models.load_model(\n",
        "    'models/best_model_5.keras',\n",
        "    custom_objects={'TransformerEncoder': TransformerEncoder,\n",
        "                    'PositionalEmbedding': PositionalEmbedding,\n",
        "                    'GCNConv': GCNConv,\n",
        "                    'GlobalSumPool': GlobalSumPool,\n",
        "                    'GCN': GCN})"
      ],
      "metadata": {
        "id": "ni4hJIm_hwi4"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "results = best_model_5.evaluate(test_dataset, verbose=1)\n",
        "precision = results[2]\n",
        "recall = results[3]\n",
        "f1_score = 2 * (precision * recall) / (precision + recall)\n",
        "print(f\"F1-Score: {f1_score:.4f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HDENgAtSiPTR",
        "outputId": "a4dd0da9-c6bd-4a52-e217-c8040553f389"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "80/80 [==============================] - 33s 270ms/step - loss: 0.0769 - accuracy: 0.9748 - precision: 0.9806 - recall: 0.9688\n",
            "F1-Score: 0.9747\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "accelerator": "TPU",
    "colab": {
      "gpuType": "V28",
      "machine_shape": "hm",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}